{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPHP-DTaYAtT"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "rawData = []\n",
        "for filepath in glob.glob(\"/dataset/*.txt\"):\n",
        "    with open(filepath, \"r\") as file:\n",
        "        content = [line.strip(\"\\n\") for line in file.readlines()]\n",
        "        rawData.append(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXUslTW9QFoD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from collections import deque\n",
        "import bisect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi9MaFHBYPGY",
        "outputId": "fed7c44b-8afc-4364-d2e1-183efc86dd45"
      },
      "outputs": [],
      "source": [
        "rawData[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7eI1DPPYRE7"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O32OmY1YYK7"
      },
      "outputs": [],
      "source": [
        "class LevelParser:\n",
        "    def __init__(self):\n",
        "        self.tile_to_idx = {\n",
        "            \"X\": 0,   #solid ground\n",
        "            \"S\": 1,   # solid breakable\n",
        "            \"-\": 2,   # passable empty\n",
        "            \"?\": 3,   # question block full\n",
        "            \"Q\": 4,   # question block empty\n",
        "            \"E\": 5,   # enemy\n",
        "            \"<\": 6,   # top-left pipe\n",
        "            \">\": 7,   # top-right pipe\n",
        "            \"[\": 8,   # left pipe\n",
        "            \"]\": 9,   # right pipe\n",
        "            \"o\": 10,  # coin\n",
        "            \"B\": 11,  # cannon top\n",
        "            \"b\": 12   # cannon bottom\n",
        "        }\n",
        "\n",
        "        self.idx_to_tile = {v: k for k, v in self.tile_to_idx.items()}\n",
        "\n",
        "        self.num_tile_types = len(self.tile_to_idx)\n",
        "\n",
        "\n",
        "    def parse_level_list(self, level_lines: List[str]) -> np.ndarray:\n",
        "        parsed_rows = []\n",
        "        for row in level_lines:\n",
        "            parsed_row = [self.tile_to_idx[char] for char in row.strip()]\n",
        "            parsed_rows.append(parsed_row)\n",
        "        level_array = np.array(parsed_rows, dtype=np.int32)\n",
        "        return level_array\n",
        "\n",
        "\n",
        "    def parse_dataset(self, levels: List[str], level_names: List[str] = None,\n",
        "                      start_x: int = 0) -> Dict:\n",
        "        if level_names is None:\n",
        "            level_names = [f\"map_{i+1}\" for i in range(len(levels))]\n",
        "\n",
        "        parsed_data = {}\n",
        "\n",
        "        for idx, (level, name) in enumerate(zip(levels, level_names)):\n",
        "            level_array = self.parse_level_list(level)\n",
        "            entry = {\n",
        "                'data': level_array,\n",
        "                'height': level_array.shape[0],\n",
        "                'width': level_array.shape[1],\n",
        "                'original': level,\n",
        "                'index': idx\n",
        "            }\n",
        "\n",
        "\n",
        "            parsed_data[name] = entry\n",
        "\n",
        "        return parsed_data\n",
        "\n",
        "\n",
        "    def decode_level(self, level_array: np.ndarray) -> str:\n",
        "        rows = []\n",
        "        for row in level_array:\n",
        "            row_str = ''.join([self.idx_to_tile[idx] for idx in row])\n",
        "            rows.append(row_str)\n",
        "        return '\\n'.join(rows)\n",
        "\n",
        "    def get_statistics(self, parsed_data: Dict) -> Dict:\n",
        "        heights = [data['height'] for data in parsed_data.values()]\n",
        "        widths = [data['width'] for data in parsed_data.values()]\n",
        "\n",
        "        tile_counts = np.zeros(self.num_tile_types, dtype=np.int32)\n",
        "        for data in parsed_data.values():\n",
        "            unique, counts = np.unique(data['data'], return_counts=True)\n",
        "            for tile_idx, count in zip(unique, counts):\n",
        "                tile_counts[tile_idx] += count\n",
        "\n",
        "        stats = {\n",
        "            'num_levels': len(parsed_data),\n",
        "            'height_range': (min(heights), max(heights)),\n",
        "            'width_range': (min(widths), max(widths)),\n",
        "            'avg_height': np.mean(heights),\n",
        "            'avg_width': np.mean(widths),\n",
        "            'tile_frequencies': {\n",
        "                self.idx_to_tile[i]: int(count)\n",
        "                for i, count in enumerate(tile_counts)\n",
        "            },\n",
        "            'total_tiles': int(tile_counts.sum())\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def visualize_level(self, level_array: np.ndarray, use_colors: bool = False):\n",
        "            print(self.decode_level(level_array))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7MI1vFuvlL9",
        "outputId": "ce417c04-1e1f-4c35-cd80-9a5973c9f20d"
      },
      "outputs": [],
      "source": [
        "parser = LevelParser()\n",
        "\n",
        "\n",
        "parsed_dataset = parser.parse_dataset(\n",
        "    levels=rawData,\n",
        "    level_names=[f\"map_{i+1}\" for i in range(1000)]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "for name, data in parsed_dataset.items():\n",
        "    print(f\"{name}: {data['data'].shape}\")\n",
        "\n",
        "stats = parser.get_statistics(parsed_dataset)\n",
        "print(f\"\\nYour dataset has {stats['num_levels']} levels\")\n",
        "print(f\"Level dimensions: {stats['height_range']} (height) x {stats['width_range']} (width)\")\n",
        "print(f\"Most common tiles:\")\n",
        "for tile, count in sorted(stats['tile_frequencies'].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "    print(f\"  {tile}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlcUNSe3vrir",
        "outputId": "5aad9064-30ca-496b-e08f-fcbac9e6a40c"
      },
      "outputs": [],
      "source": [
        "parsed_dataset['map_1']['original']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9dvI1Tbx4dv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from typing import List, Dict\n",
        "\n",
        "class PatchDifficultyEvaluator:\n",
        "    def __init__(self, parser):\n",
        "        self.parser = parser\n",
        "        self.EMPTY = parser.tile_to_idx['-']\n",
        "        self.GROUND = parser.tile_to_idx['X']\n",
        "        self.BREAKABLE = parser.tile_to_idx['S']\n",
        "        self.COIN = parser.tile_to_idx['o']\n",
        "        self.ENEMY = parser.tile_to_idx['E']\n",
        "        self.PIPE_LEFT = parser.tile_to_idx['[']\n",
        "        self.PIPE_RIGHT = parser.tile_to_idx[']']\n",
        "        self.QUESTION = parser.tile_to_idx['Q']\n",
        "        self.BRICK_LEFT = parser.tile_to_idx['<']\n",
        "        self.BRICK_RIGHT = parser.tile_to_idx['>']\n",
        "        self.CANNON_BOTTOM = parser.tile_to_idx['b']\n",
        "        self.CANNON_TOP = parser.tile_to_idx['B']\n",
        "\n",
        "        self.MAX_ENEMY_DENSITY = 0.15\n",
        "        self.MAX_CANNON_DENSITY = 0.15\n",
        "        self.MAX_PIPE_DENSITY = 0.15\n",
        "        self.MAX_JUMP_DENSITY = 0.2\n",
        "        self.MAX_PLATFORM_DENSITY = 0.1\n",
        "\n",
        "    def _count_enemies(self, patch):\n",
        "        return np.sum(patch == self.ENEMY)\n",
        "\n",
        "    def _count_cannons(self, patch):\n",
        "        height, width = patch.shape\n",
        "        cannon_count = 0\n",
        "\n",
        "        for col in range(width):\n",
        "            has_cannon_bottom = np.any(patch[:, col] == self.CANNON_BOTTOM)\n",
        "            if has_cannon_bottom:\n",
        "                cannon_count += 1\n",
        "\n",
        "        return cannon_count\n",
        "\n",
        "    def _count_pipes(self, patch):\n",
        "        height, width = patch.shape\n",
        "        pipe_count = 0\n",
        "\n",
        "        for col in range(width):\n",
        "            has_pipe_left = np.any(patch[:, col] == self.PIPE_LEFT)\n",
        "            if has_pipe_left:\n",
        "                pipe_count += 1\n",
        "\n",
        "        return pipe_count\n",
        "\n",
        "    def _count_jumps(self, patch):\n",
        "        height, width = patch.shape\n",
        "        jumps = 0\n",
        "\n",
        "        ground_floor = patch[height - 1]\n",
        "        gap_length = 0\n",
        "\n",
        "        for col in range(width):\n",
        "            if ground_floor[col] == self.EMPTY:\n",
        "                gap_length += 1\n",
        "            else:\n",
        "                if gap_length > 0:\n",
        "                    jumps += 1\n",
        "                    if gap_length > 4:\n",
        "                        jumps += (gap_length - 2) * 0.5\n",
        "                gap_length = 0\n",
        "\n",
        "        if gap_length > 0:\n",
        "            jumps += 1\n",
        "            if gap_length > 2:\n",
        "                jumps += (gap_length - 2) * 0.5\n",
        "\n",
        "        return int(jumps)\n",
        "\n",
        "    def _count_elevated_platforms(self, patch):\n",
        "            height, width = patch.shape\n",
        "            platforms = 0\n",
        "\n",
        "            PLATFORM_TILES = {self.GROUND, self.BREAKABLE, self.QUESTION}\n",
        "\n",
        "            for row in range(height - 1):\n",
        "                in_platform = False\n",
        "                platform_start = -1\n",
        "\n",
        "                for col in range(width):\n",
        "                    if patch[row, col] in PLATFORM_TILES:\n",
        "                        if not in_platform:\n",
        "                            in_platform = True\n",
        "                            platform_start = col\n",
        "                    else:\n",
        "                        if in_platform:\n",
        "                            is_floating = False\n",
        "                            for c in range(platform_start, col):\n",
        "                                for r in range(row + 1, height):\n",
        "                                    if patch[r, c] == self.EMPTY:\n",
        "                                        is_floating = True\n",
        "                                        break\n",
        "                                if is_floating:\n",
        "                                    break\n",
        "\n",
        "                            if is_floating:\n",
        "                                platforms += 1\n",
        "\n",
        "                            in_platform = False\n",
        "\n",
        "                if in_platform:\n",
        "                    is_floating = False\n",
        "                    for c in range(platform_start, width):\n",
        "                        for r in range(row + 1, height):\n",
        "                            if patch[r, c] == self.EMPTY:\n",
        "                                is_floating = True\n",
        "                                break\n",
        "                        if is_floating:\n",
        "                            break\n",
        "\n",
        "                    if is_floating:\n",
        "                        platforms += 1\n",
        "\n",
        "            return platforms\n",
        "\n",
        "\n",
        "    def evaluate_patch(self, patch, metadata=None):\n",
        "        height, width = patch.shape\n",
        "        total_tiles = height * width\n",
        "\n",
        "        enemies = self._count_enemies(patch)\n",
        "        cannons = self._count_cannons(patch)\n",
        "        pipes = self._count_pipes(patch)\n",
        "        jumps = self._count_jumps(patch)\n",
        "        platforms = self._count_elevated_platforms(patch)\n",
        "\n",
        "        enemy_density = enemies / width\n",
        "        cannon_density = cannons / width\n",
        "        pipe_density = pipes / width\n",
        "        jump_density = jumps / width\n",
        "        platform_density = platforms / width\n",
        "\n",
        "        enemy_term = min(enemy_density / self.MAX_ENEMY_DENSITY, 1.0)\n",
        "        cannon_term = min(cannon_density / self.MAX_CANNON_DENSITY, 1.0)\n",
        "        jump_term = min(jump_density / self.MAX_JUMP_DENSITY, 1.0)\n",
        "        pipe_term = min(pipe_density / self.MAX_PIPE_DENSITY, 1.0)\n",
        "        platform_term = min(platform_density / self.MAX_PLATFORM_DENSITY, 1.0)\n",
        "\n",
        "        raw_diff = (\n",
        "            0.60 * enemy_term +\n",
        "            0.30 * cannon_term +\n",
        "            0.20 * jump_term +\n",
        "            0.30 * platform_term +\n",
        "            0.20 * pipe_term\n",
        "        )\n",
        "\n",
        "        diff_score = min(raw_diff , 1.0)\n",
        "\n",
        "\n",
        "        result = {\n",
        "            \"metadata\": metadata,\n",
        "            \"counts\": {\n",
        "                \"enemies\": enemies,\n",
        "                \"cannons\": cannons,\n",
        "                \"pipes\": pipes,\n",
        "                \"jumps\": jumps,\n",
        "                \"platforms\": platforms,\n",
        "                \"total_tiles\": total_tiles\n",
        "            },\n",
        "            \"densities\": {\n",
        "                \"enemy_density\": round(enemy_density, 3),\n",
        "                \"cannon_density\": round(cannon_density, 3),\n",
        "                \"pipe_density\": round(pipe_density, 3),\n",
        "                \"jump_density\": round(jump_density, 3),\n",
        "                \"platform_density\": round(platform_density, 3)\n",
        "            },\n",
        "            \"scores\": {\n",
        "                \"difficulty_score\": round(diff_score, 3),\n",
        "            },\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def evaluate_patches_batch(self, patches, metadata_list=None):\n",
        "        if metadata_list is None:\n",
        "            metadata_list = [None] * len(patches)\n",
        "\n",
        "        results = []\n",
        "        for i in range(len(patches)):\n",
        "            result = self.evaluate_patch(patches[i], metadata_list[i])\n",
        "            results.append(result)\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZV4aG650gFh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "\n",
        "class PatchExtractor:\n",
        "    def __init__(self, patch_height: int = 14, patch_width: int = 16,\n",
        "                 stride: int = 4, vertical_stride: int = 8):\n",
        "        self.patch_height = patch_height\n",
        "        self.patch_width = patch_width\n",
        "        self.stride = stride\n",
        "        self.vertical_stride = vertical_stride\n",
        "    def extract_patches_from_level(self, level_meta,\n",
        "                                   level_name: str = \"\",\n",
        "                                   ):\n",
        "        height, width = level_meta['data'].shape\n",
        "        patches = []\n",
        "        metadata = []\n",
        "        patch_idx = 0\n",
        "\n",
        "        y_positions = list(range(0, height - self.patch_height + 1, self.vertical_stride))\n",
        "        x_positions = list(range(0, width - self.patch_width + 1, self.stride))\n",
        "        if len(y_positions) == 0:\n",
        "            y_positions = [max(0, height - self.patch_height)]\n",
        "        elif y_positions[-1] + self.patch_height < height:\n",
        "            y_positions.append(height - self.patch_height)\n",
        "\n",
        "        if len(x_positions) == 0:\n",
        "            x_positions = [max(0, width - self.patch_width)]\n",
        "        elif x_positions[-1] + self.patch_width < width:\n",
        "            x_positions.append(width - self.patch_width)\n",
        "\n",
        "        for y in y_positions:\n",
        "            for x in x_positions:\n",
        "                patch = level_meta['data'][y:y + self.patch_height, x:x + self.patch_width].copy()\n",
        "                patches.append(patch)\n",
        "                meta = {\n",
        "                    'level_name': level_name,\n",
        "                    'patch_idx': patch_idx,\n",
        "                    'x_start': x,\n",
        "                    'x_end': x + self.patch_width,\n",
        "                    'y_start': y,\n",
        "                    'y_end': y + self.patch_height,\n",
        "                    'level_height': height,\n",
        "                    'final_score': 0,\n",
        "                }\n",
        "\n",
        "                metadata.append(meta)\n",
        "                patch_idx += 1\n",
        "\n",
        "        patches_array = np.stack(patches, axis=0) if patches else np.empty((0, self.patch_height, self.patch_width), dtype=level_meta['data'].dtype)\n",
        "        return patches_array, metadata\n",
        "    def extract_patches_from_dataset(self, parsed_dataset: Dict) -> Tuple[np.ndarray, List[Dict]]:\n",
        "        all_patches = []\n",
        "        all_metadata = []\n",
        "\n",
        "        for level_name, level_data in parsed_dataset.items():\n",
        "            patches, metadata = self.extract_patches_from_level(level_data, level_name)\n",
        "            if len(patches) > 0:\n",
        "                all_patches.append(patches)\n",
        "                all_metadata.extend(metadata)\n",
        "\n",
        "        if all_patches:\n",
        "            all_patches_array = np.concatenate(all_patches, axis=0)\n",
        "        else:\n",
        "            all_patches_array = np.empty((0, self.patch_height, self.patch_width), dtype=np.int32)\n",
        "\n",
        "        return all_patches_array, all_metadata\n",
        "\n",
        "    def get_patch_statistics(self, patches: np.ndarray, metadata: List[Dict]) -> Dict:\n",
        "        if len(patches) == 0:\n",
        "            return {'num_patches': 0}\n",
        "\n",
        "        level_patch_counts = {}\n",
        "        for meta in metadata:\n",
        "            lvl = meta['level_name']\n",
        "            level_patch_counts[lvl] = level_patch_counts.get(lvl, 0) + 1\n",
        "\n",
        "        unique_tiles, tile_counts = np.unique(patches, return_counts=True)\n",
        "\n",
        "        stats = {\n",
        "            'num_patches': len(patches),\n",
        "            'patch_shape': patches.shape,\n",
        "            'patches_per_level': level_patch_counts,\n",
        "            'avg_patches_per_level': float(np.mean(list(level_patch_counts.values()))),\n",
        "            'min_patches_per_level': int(min(level_patch_counts.values())),\n",
        "            'max_patches_per_level': int(max(level_patch_counts.values())),\n",
        "            'tile_distribution': {int(t): int(c) for t, c in zip(unique_tiles, tile_counts)},\n",
        "            'total_tiles_in_patches': int(tile_counts.sum())\n",
        "        }\n",
        "        return stats\n",
        "\n",
        "    def reconstruct_level_from_patches(self, patches: np.ndarray, metadata: List[Dict]) -> np.ndarray:\n",
        "        if not metadata:\n",
        "            return np.array([])\n",
        "\n",
        "        original_width = max(m['x_end'] for m in metadata)\n",
        "        original_height = max(m['y_end'] for m in metadata)\n",
        "\n",
        "        reconstructed = np.zeros((original_height, original_width), dtype=np.float32)\n",
        "        counts = np.zeros((original_height, original_width), dtype=np.float32)\n",
        "\n",
        "        for patch, meta in zip(patches, metadata):\n",
        "            y_start, y_end = meta['y_start'], meta['y_end']\n",
        "            x_start, x_end = meta['x_start'], meta['x_end']\n",
        "            reconstructed[y_start:y_end, x_start:x_end] += patch\n",
        "            counts[y_start:y_end, x_start:x_end] += 1\n",
        "\n",
        "        reconstructed = reconstructed / np.maximum(counts, 1)\n",
        "        reconstructed = np.round(reconstructed).astype(np.int32)\n",
        "        return reconstructed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOwB-L5lH-U-"
      },
      "source": [
        "# Test Patch Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUWx5YOd0Tww",
        "outputId": "42bd339d-5d0d-403d-c535-95078b4501a3"
      },
      "outputs": [],
      "source": [
        "extractor = PatchExtractor(\n",
        "    patch_height=14,\n",
        "    patch_width=16,\n",
        "    stride=4,\n",
        "    vertical_stride=4\n",
        ")\n",
        "\n",
        "patches, metadata = extractor.extract_patches_from_level(\n",
        "    level_meta=parsed_dataset['map_1'],\n",
        "    level_name=\"sample_level\"\n",
        ")\n",
        "\n",
        "print(f\"\\nExtracted {len(patches)} patches from sample level\")\n",
        "print(f\"Patches shape: {patches.shape}\")\n",
        "\n",
        "patch_stats = extractor.get_patch_statistics(patches, metadata)\n",
        "print(f\"\\nPatch Statistics:\")\n",
        "print(f\"  Total patches: {patch_stats['num_patches']}\")\n",
        "print(f\"  Patches shape: {patch_stats['patch_shape']}\")\n",
        "print(f\"  Total tiles in all patches: {patch_stats['total_tiles_in_patches']}\")\n",
        "\n",
        "\n",
        "patch_evaluator = PatchDifficultyEvaluator(parser)\n",
        "patch_evaluation_results = patch_evaluator.evaluate_patches_batch(patches, metadata)\n",
        "for i, result in enumerate(patch_evaluation_results):\n",
        "    metadata[i]['final_score'] = result['scores']['difficulty_score']\n",
        "\n",
        "num_to_show = min(122, len(patches))\n",
        "print(f\"\\nShowing {num_to_show} sample patches:\\n\" + \"=\" * 60)\n",
        "\n",
        "for i in range(num_to_show):\n",
        "    meta = metadata[i]\n",
        "\n",
        "    difficulty_eval = patch_evaluation_results[i]\n",
        "    diff_score = difficulty_eval['scores']['difficulty_score']\n",
        "\n",
        "    enemy_count = difficulty_eval['counts']['enemies']\n",
        "    pipe_count = difficulty_eval['counts']['pipes']\n",
        "    jump_count = difficulty_eval['counts']['jumps']\n",
        "    platform_count = difficulty_eval['counts']['platforms']\n",
        "\n",
        "    print(f\"\\nPatch {i+1} from {meta['level_name']} \"\n",
        "          f\"(x: {meta['x_start']}-{meta['x_end']}, y: {meta['y_start']}-{meta['y_end']}, \"\n",
        "          f\"difficulty: {meta.get('final_score', 0):.3f})\\\"\")\n",
        "    print(f\"Enemies: {enemy_count}, Pipes: {pipe_count}, Jumps: {jump_count}, Platforms: {platform_count}\")\n",
        "    print(\"-\" * 60)\n",
        "    decoded_patch = parser.decode_level(patches[i])\n",
        "    print(decoded_patch)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RECONSTRUCTION TEST\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "reconstructed = extractor.reconstruct_level_from_patches(\n",
        "    patches,\n",
        "    metadata,\n",
        ")\n",
        "\n",
        "print(f\"\\nOriginal shape: {parsed_dataset['map_1']['data'].shape}\")\n",
        "print(f\"Reconstructed shape: {reconstructed.shape}\")\n",
        "\n",
        "match_percentage = np.mean(reconstructed == parsed_dataset['map_1']['data']) * 100\n",
        "print(f\"Reconstruction accuracy: {match_percentage:.2f}%\")\n",
        "\n",
        "if match_percentage < 100:\n",
        "    print(\"\\nNote: Small differences may occur at boundaries due to averaging/rounding\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyWOXP8u8wLQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOMO-aFJzEx6",
        "outputId": "17e7004b-16e6-43e4-9ff4-70be5fee7d4e"
      },
      "outputs": [],
      "source": [
        "metadata[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L88G8B4Ex_7J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import Tuple, Dict, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class PatchDatasetCreator(Dataset):\n",
        "\n",
        "    def __init__(self, patches: np.ndarray, difficulties: Optional[np.ndarray] = None):\n",
        "        self.patches = torch.from_numpy(patches).long()\n",
        "\n",
        "        if difficulties is not None:\n",
        "            diffs = np.asarray(difficulties, dtype=np.float32).reshape(-1)  # [N]\n",
        "            assert diffs.shape[0] == self.patches.shape[0]\n",
        "            self.difficulties = torch.from_numpy(diffs).float()  # [N]\n",
        "        else:\n",
        "            self.difficulties = None\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patches)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.difficulties is None:\n",
        "            return self.patches[idx]\n",
        "        else:\n",
        "            return self.patches[idx], self.difficulties[idx]\n",
        "\n",
        "\n",
        "class PatchEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_tile_types: int = 13,\n",
        "                 embedding_dim: int = 32,\n",
        "                 latent_dim: int = 128,\n",
        "                 patch_height: int = 14,\n",
        "                 patch_width: int = 16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_tile_types = num_tile_types\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.patch_height = patch_height\n",
        "        self.patch_width = patch_width\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "        self.tile_embedding = nn.Embedding(num_tile_types, embedding_dim)\n",
        "        self.conv1 = nn.Conv2d(embedding_dim, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, embedding_dim, patch_height, patch_width)\n",
        "            dummy = self.leaky_relu(self.bn1(self.conv1(dummy)))\n",
        "            dummy = self.leaky_relu(self.bn2(self.conv2(dummy)))\n",
        "            dummy = self.leaky_relu(self.bn3(self.conv3(dummy)))\n",
        "            dummy = self.leaky_relu(self.bn4(self.conv4(dummy)))\n",
        "            self.flattened_size = dummy.numel()\n",
        "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
        "        self.fc2 = nn.Linear(512, latent_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size = x.shape[0]\n",
        "        x = self.tile_embedding(x)           # [B, H, W, E]\n",
        "        x = x.permute(0, 3, 1, 2)           # [B, E, H, W]\n",
        "        x = self.leaky_relu(self.bn1(self.conv1(x)))\n",
        "        x = self.leaky_relu(self.bn2(self.conv2(x)))\n",
        "        x = self.leaky_relu(self.bn3(self.conv3(x)))\n",
        "        x = self.leaky_relu(self.bn4(self.conv4(x)))\n",
        "        x = x.reshape(batch_size, -1)\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_tile_types: int = 13,\n",
        "                 latent_dim: int = 128,\n",
        "                 patch_height: int = 14,\n",
        "                 patch_width: int = 16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_tile_types = num_tile_types\n",
        "        self.latent_dim = latent_dim\n",
        "        self.patch_height = patch_height\n",
        "        self.patch_width = patch_width\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.start_h = 4\n",
        "        self.start_w = 4\n",
        "        self.start_channels = 512\n",
        "        self.fc1 = nn.Linear(latent_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, self.start_channels * self.start_h * self.start_w)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.deconv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.deconv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(256)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.final_conv = nn.Conv2d(64, num_tile_types, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size = z.shape[0]\n",
        "        x = self.leaky_relu(self.fc1(z))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = x.reshape(batch_size, self.start_channels, self.start_h, self.start_w)\n",
        "        x = self.leaky_relu(self.bn1(self.deconv1(x)))\n",
        "        x = self.leaky_relu(self.bn2(self.deconv2(x)))\n",
        "        x = self.leaky_relu(self.bn3(self.deconv3(x)))\n",
        "        x = self.final_conv(x)\n",
        "        x = x[:, :, :self.patch_height, :self.patch_width]\n",
        "\n",
        "        return x\n",
        "class LatentNormalizer:\n",
        "\n",
        "    def __init__(self, target_norm: float = 11.0):\n",
        "        self.target_norm = target_norm\n",
        "        self.scale_factor = None\n",
        "        self.original_mean_norm = None\n",
        "\n",
        "    def fit(self, latents: torch.Tensor):\n",
        "        norms = latents.norm(dim=-1)\n",
        "        self.original_mean_norm = norms.mean().item()\n",
        "        self.scale_factor = self.target_norm / self.original_mean_norm\n",
        "\n",
        "        print(f\"Latent Normalizer fitted:\")\n",
        "        print(f\"  Original mean norm: {self.original_mean_norm:.2f}\")\n",
        "        print(f\"  Target mean norm: {self.target_norm:.2f}\")\n",
        "        print(f\"  Scale factor: {self.scale_factor:.6f}\")\n",
        "\n",
        "    def fit_from_dataloader(self, dataloader: DataLoader, model: nn.Module, device: str = 'cuda'):\n",
        "        model.eval()\n",
        "        all_norms = []\n",
        "\n",
        "        print(\"Computing latent statistics from data...\")\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                if isinstance(batch, (list, tuple)):\n",
        "                    patches = batch[0]\n",
        "                else:\n",
        "                    patches = batch\n",
        "\n",
        "                patches = patches.to(device)\n",
        "                latents = model.encode(patches)\n",
        "                norms = latents.norm(dim=-1)\n",
        "                all_norms.append(norms.cpu())\n",
        "\n",
        "        all_norms = torch.cat(all_norms)\n",
        "        self.original_mean_norm = all_norms.mean().item()\n",
        "        self.scale_factor = self.target_norm / self.original_mean_norm\n",
        "\n",
        "        print(f\"Latent Normalizer fitted:\")\n",
        "        print(f\"  Original mean norm: {self.original_mean_norm:.2f}\")\n",
        "        print(f\"  Original std: {all_norms.std().item():.2f}\")\n",
        "        print(f\"  Target mean norm: {self.target_norm:.2f}\")\n",
        "        print(f\"  Scale factor: {self.scale_factor:.6f}\")\n",
        "\n",
        "    def normalize(self, latents: torch.Tensor) -> torch.Tensor:\n",
        "        return latents * self.scale_factor\n",
        "\n",
        "    def denormalize(self, latents: torch.Tensor) -> torch.Tensor:\n",
        "        return latents / self.scale_factor\n",
        "\n",
        "    def save(self, path: str):\n",
        "        torch.save({\n",
        "            'scale_factor': self.scale_factor,\n",
        "            'target_norm': self.target_norm,\n",
        "            'original_mean_norm': self.original_mean_norm\n",
        "        }, path)\n",
        "        print(f\"Latent normalizer saved to {path}\")\n",
        "\n",
        "    def load(self, path: str):\n",
        "        checkpoint = torch.load(path)\n",
        "        self.scale_factor = checkpoint['scale_factor']\n",
        "        self.target_norm = checkpoint['target_norm']\n",
        "        self.original_mean_norm = checkpoint['original_mean_norm']\n",
        "        print(f\"Latent normalizer loaded from {path}\")\n",
        "        print(f\"  Scale factor: {self.scale_factor:.6f}\")\n",
        "        print(f\"  Original norm: {self.original_mean_norm:.2f} -> Target: {self.target_norm:.2f}\")\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_tile_types: int = 13,\n",
        "                 embedding_dim: int = 32,\n",
        "                 latent_dim: int = 128,\n",
        "                 patch_height: int = 14,\n",
        "                 patch_width: int = 16\n",
        "              ):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_tile_types = num_tile_types\n",
        "\n",
        "        self.encoder = PatchEncoder(\n",
        "            num_tile_types=num_tile_types,\n",
        "            embedding_dim=embedding_dim,\n",
        "            latent_dim=latent_dim,\n",
        "            patch_height=patch_height,\n",
        "            patch_width=patch_width\n",
        "        )\n",
        "\n",
        "        self.decoder = PatchDecoder(\n",
        "            num_tile_types=num_tile_types,\n",
        "            latent_dim=latent_dim,\n",
        "            patch_height=patch_height,\n",
        "            patch_width=patch_width\n",
        "        )\n",
        "        self.difficulty_head = nn.Sequential(\n",
        "            nn.Linear(latent_dim, latent_dim // 2),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(latent_dim // 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, return_difficulty: bool = False):\n",
        "        latent = self.encoder(x)\n",
        "        recon = self.decoder(latent)\n",
        "        z = latent\n",
        "\n",
        "        if return_difficulty:\n",
        "            diff_pred = self.difficulty_head(z).squeeze(1)\n",
        "            return recon, z, diff_pred\n",
        "        else:\n",
        "            return recon, z\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def reconstruct(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        logits, _ = self.forward(x)\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        return predictions\n",
        "\n",
        "    def predict_difficulty_from_latent(self, latent: torch.Tensor) -> torch.Tensor:\n",
        "        return self.difficulty_head(latent).squeeze(1)\n",
        "\n",
        "    def predict_difficulty(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        _, latent = self.forward(x)\n",
        "        return self.predict_difficulty_from_latent(latent)\n",
        "\n",
        "\n",
        "class AutoencoderTrainer:\n",
        "    def __init__(self,\n",
        "                 model: Autoencoder,\n",
        "                 learning_rate: float = 1e-4,\n",
        "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "                 difficulty_loss_weight: float = 0.0):\n",
        "\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.difficulty_loss_weight = difficulty_loss_weight\n",
        "        self.difficulty_criterion = nn.MSELoss()\n",
        "\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train_epoch(self, train_loader: DataLoader) -> float:\n",
        "        self.model.train()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            if isinstance(batch, (list, tuple)):\n",
        "                patches, diffs = batch\n",
        "                patches = patches.to(self.device)\n",
        "                diffs = diffs.to(self.device).view(-1)\n",
        "            else:\n",
        "                patches = batch.to(self.device)\n",
        "                diffs = None\n",
        "            if self.difficulty_loss_weight > 0.0 and diffs is not None:\n",
        "                reconstruction, latent, diff_pred = self.model(patches, return_difficulty=True)\n",
        "            else:\n",
        "                reconstruction, latent = self.model(patches)\n",
        "                diff_pred = None\n",
        "            recon_loss = self.criterion(reconstruction, patches)\n",
        "\n",
        "            loss = recon_loss\n",
        "            if (self.difficulty_loss_weight > 0.0) and (diffs is not None):\n",
        "                diff_loss = self.difficulty_criterion(diff_pred, diffs)\n",
        "                loss = loss + self.difficulty_loss_weight * diff_loss\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / max(1, num_batches)\n",
        "        return avg_loss\n",
        "\n",
        "    def validate(self, val_loader: DataLoader) -> Tuple[float, float]:\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        total_accuracy = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                if isinstance(batch, (list, tuple)):\n",
        "                    patches, diffs = batch\n",
        "                    patches = patches.to(self.device)\n",
        "                    diffs = diffs.to(self.device).view(-1)\n",
        "                else:\n",
        "                    patches = batch.to(self.device)\n",
        "                    diffs = None\n",
        "                if self.difficulty_loss_weight > 0.0 and diffs is not None:\n",
        "                    reconstruction, latent, diff_pred = self.model(patches, return_difficulty=True)\n",
        "                else:\n",
        "                    reconstruction, latent = self.model(patches)\n",
        "                    diff_pred = None\n",
        "\n",
        "                recon_loss = self.criterion(reconstruction, patches)\n",
        "                loss = recon_loss\n",
        "                if (self.difficulty_loss_weight > 0.0) and (diffs is not None):\n",
        "                    diff_loss = self.difficulty_criterion(diff_pred, diffs)\n",
        "                    loss = loss + self.difficulty_loss_weight * diff_loss\n",
        "\n",
        "                predictions = torch.argmax(reconstruction, dim=1)\n",
        "                accuracy = (predictions == patches).float().mean()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_accuracy += accuracy.item()\n",
        "                num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / max(1, num_batches)\n",
        "        avg_accuracy = total_accuracy / max(1, num_batches)\n",
        "        return avg_loss, avg_accuracy\n",
        "\n",
        "    def train(self,\n",
        "              train_loader: DataLoader,\n",
        "              val_loader: Optional[DataLoader] = None,\n",
        "              num_epochs: int = 100,\n",
        "              print_every: int = 10):\n",
        "\n",
        "        print(f\"Training on device: {self.device}\")\n",
        "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
        "        print(f\"Difficulty loss weight: {self.difficulty_loss_weight}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = self.train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "            if val_loader is not None:\n",
        "                val_loss, val_accuracy = self.validate(val_loader)\n",
        "                self.val_losses.append(val_loss)\n",
        "\n",
        "                if (epoch + 1) % print_every == 0:\n",
        "                    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "                          f\"Train Loss: {train_loss:.4f} | \"\n",
        "                          f\"Val Loss: {val_loss:.4f} | \"\n",
        "                          f\"Val Accuracy: {val_accuracy:.4f}\")\n",
        "            else:\n",
        "                if (epoch + 1) % print_every == 0:\n",
        "                    print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        print(\"-\" * 70)\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "    def plot_losses(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(self.train_losses, label='Train Loss')\n",
        "        if self.val_losses:\n",
        "            plt.plot(self.val_losses, label='Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Autoencoder Training Progress')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, path: str):\n",
        "        checkpoint = {\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'train_losses': self.train_losses,\n",
        "            'val_losses': self.val_losses,\n",
        "            'difficulty_loss_weight': self.difficulty_loss_weight\n",
        "        }\n",
        "\n",
        "        torch.save(checkpoint, path)\n",
        "        print(f\"Model saved to {path}\")\n",
        "\n",
        "    def load_model(self, path: str):\n",
        "        checkpoint = torch.load(path, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.train_losses = checkpoint['train_losses']\n",
        "        self.val_losses = checkpoint['val_losses']\n",
        "        self.difficulty_loss_weight = checkpoint.get('difficulty_loss_weight', 0.0)\n",
        "\n",
        "        print(f\"Model loaded from {path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhgodJoKz5MK"
      },
      "source": [
        "**create latents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dn3z9A-NFeI"
      },
      "outputs": [],
      "source": [
        "all_patches, metadata = extractor.extract_patches_from_dataset(\n",
        "parsed_dataset\n",
        ")\n",
        "patch_evaluator = PatchDifficultyEvaluator(parser)\n",
        "patch_evaluation_results = patch_evaluator.evaluate_patches_batch(all_patches, metadata)\n",
        "for i, result in enumerate(patch_evaluation_results):\n",
        "  metadata[i]['final_score'] = result['scores']['difficulty_score']\n",
        "all_difficulties = [(d['final_score']) for d in metadata]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSwtiqWWNGko",
        "outputId": "9c00440b-c082-4611-cb8d-a634f2745cce"
      },
      "outputs": [],
      "source": [
        "np.array(all_difficulties).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "_U09U1DiMVBY",
        "outputId": "b504e818-d0d8-4517-fe02-84b5a42946d8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "data = all_difficulties\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "counts, bins, patches = plt.hist(\n",
        "    data,\n",
        "    bins='auto',\n",
        "    alpha=0.6,\n",
        "    edgecolor='black',\n",
        "    linewidth=1.2\n",
        ")\n",
        "\n",
        "kde = gaussian_kde(data)\n",
        "x_vals = np.linspace(min(data), max(data), 300)\n",
        "kde_vals = kde(x_vals)\n",
        "\n",
        "scale = max(counts) / max(kde_vals)\n",
        "plt.plot(x_vals, kde_vals * scale, linewidth=3)\n",
        "\n",
        "plt.grid(alpha=0.25)\n",
        "plt.xlabel(\"Difficulty\", fontsize=14)\n",
        "plt.ylabel(\"Number of patches\", fontsize=14)\n",
        "plt.title(\"patch Difficulty Distribution\", fontsize=18, pad=15)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT3gkL7ezA_Z",
        "outputId": "25092886-bff7-4073-88eb-75261e77bebc"
      },
      "outputs": [],
      "source": [
        "print(\"Mario Level Autoencoder\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "dataset = PatchDatasetCreator(all_patches, difficulties=all_difficulties)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Train size: {train_size}, Val size: {val_size}\")\n",
        "print(\"-\" * 70)\n",
        "model = Autoencoder(\n",
        "  num_tile_types=13,\n",
        "  embedding_dim=32,\n",
        "  latent_dim=128,\n",
        "  patch_height=14,\n",
        "  patch_width=16,\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "print(f\"Latent dimension: {model.latent_dim}\")\n",
        "print(\"-\" * 70)\n",
        "trainer = AutoencoderTrainer(model, learning_rate=1e-4, difficulty_loss_weight=10.0)\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "trainer.train(train_loader, val_loader, num_epochs=100, print_every=5)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Testing reconstruction on a sample:\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample = all_patches[0:1]\n",
        "    sample_tensor = torch.from_numpy(sample).long().to(trainer.device)\n",
        "    latent = model.encode(sample_tensor)\n",
        "    reconstruction = model.reconstruct(sample_tensor)\n",
        "\n",
        "    print(f\"Original shape: {sample.shape}\")\n",
        "    print(f\"Latent shape: {latent.shape}\")\n",
        "    print(f\"Reconstruction shape: {reconstruction.shape}\")\n",
        "    accuracy = (reconstruction.cpu().numpy() == sample).mean()\n",
        "    print(f\"Reconstruction accuracy: {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYiKGQFKzIiw",
        "outputId": "aa172ed5-c075-4183-ac47-6f7b091abace"
      },
      "outputs": [],
      "source": [
        "trainer.save_model('/content/Output/AutoEncoder.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTC2F8KnKKo5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "\n",
        "class NoiseSchedule:\n",
        "    def __init__(self,\n",
        "                 num_timesteps: int = 500,\n",
        "                 beta_start: float = 1e-4,\n",
        "                 beta_end: float = 0.02,\n",
        "                 schedule_type: str = 'linear',\n",
        "                 device: str = 'cpu',\n",
        "                 min_alpha_cumprod: float = 1e-4):\n",
        "        self.num_timesteps = num_timesteps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.schedule_type = schedule_type\n",
        "        self.device = device\n",
        "        self.min_alpha_cumprod = min_alpha_cumprod\n",
        "        self.betas = self._linear_schedule()\n",
        "\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "        self.alphas_cumprod = torch.clamp(self.alphas_cumprod, min=min_alpha_cumprod, max=1.0)\n",
        "\n",
        "        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0]), self.alphas_cumprod[:-1]])\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
        "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas.clamp(min=1e-8))\n",
        "        safe_denominator = torch.clamp(1.0 - self.alphas_cumprod, min=1e-8)\n",
        "        self.posterior_variance = self.betas * (1.0 - self.alphas_cumprod_prev) / safe_denominator\n",
        "        self.posterior_variance = torch.clamp(self.posterior_variance, min=1e-8, max=1.0)\n",
        "        self._to_device(device)\n",
        "        self._verify_schedule()\n",
        "\n",
        "    def _linear_schedule(self) -> torch.Tensor:\n",
        "        return torch.linspace(self.beta_start, self.beta_end, self.num_timesteps)\n",
        "\n",
        "\n",
        "    def _to_device(self, device: str):\n",
        "        self.betas = self.betas.to(device)\n",
        "        self.alphas = self.alphas.to(device)\n",
        "        self.alphas_cumprod = self.alphas_cumprod.to(device)\n",
        "        self.alphas_cumprod_prev = self.alphas_cumprod_prev.to(device)\n",
        "        self.sqrt_alphas_cumprod = self.sqrt_alphas_cumprod.to(device)\n",
        "        self.sqrt_one_minus_alphas_cumprod = self.sqrt_one_minus_alphas_cumprod.to(device)\n",
        "        self.sqrt_recip_alphas = self.sqrt_recip_alphas.to(device)\n",
        "        self.posterior_variance = self.posterior_variance.to(device)\n",
        "\n",
        "    def _verify_schedule(self):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Noise Schedule Verification ({self.schedule_type}, T={self.num_timesteps})\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"  t=0 (clean):\")\n",
        "        print(f\"    alphas_cumprod: {self.alphas_cumprod[0]:.6f}\")\n",
        "        print(f\"    sqrt_alphas_cumprod: {self.sqrt_alphas_cumprod[0]:.6f}\")\n",
        "        print(f\"  t={self.num_timesteps-1} (noisy):\")\n",
        "        print(f\"    alphas_cumprod: {self.alphas_cumprod[-1]:.6f}\")\n",
        "        print(f\"    sqrt_alphas_cumprod: {self.sqrt_alphas_cumprod[-1]:.6f}\")\n",
        "        print(f\"  Minimum sqrt_alphas_cumprod: {self.sqrt_alphas_cumprod.min():.6f}\")\n",
        "        print(f\"  Maximum sqrt_alphas_cumprod: {self.sqrt_alphas_cumprod.max():.6f}\")\n",
        "        if self.sqrt_alphas_cumprod.min() < 0.01:\n",
        "            print(f\" WARNING: sqrt_alphas_cumprod minimum is very small!\")\n",
        "            print(f\"Consider increasing min_alpha_cumprod parameter\")\n",
        "        else:\n",
        "            print(f\"   Schedule is numerically stable\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "    def visualize_schedule(self):\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "        timesteps = np.arange(self.num_timesteps)\n",
        "        axes[0, 0].plot(timesteps, self.betas.cpu().numpy())\n",
        "        axes[0, 0].set_title('Beta Schedule (Noise Variance)')\n",
        "        axes[0, 0].set_xlabel('Timestep')\n",
        "        axes[0, 0].set_ylabel('_t')\n",
        "        axes[0, 0].grid(True)\n",
        "        axes[0, 1].plot(timesteps, self.alphas_cumprod.cpu().numpy())\n",
        "        axes[0, 1].set_title('Cumulative Alpha Product')\n",
        "        axes[0, 1].set_xlabel('Timestep')\n",
        "        axes[0, 1].set_ylabel('_t')\n",
        "        axes[0, 1].grid(True)\n",
        "        axes[0, 1].axhline(y=self.min_alpha_cumprod, color='r', linestyle='--',\n",
        "                          label=f'Min clamp ({self.min_alpha_cumprod})')\n",
        "        axes[0, 1].legend()\n",
        "        axes[1, 0].plot(timesteps, self.sqrt_alphas_cumprod.cpu().numpy(), label='Signal')\n",
        "        axes[1, 0].plot(timesteps, self.sqrt_one_minus_alphas_cumprod.cpu().numpy(), label='Noise')\n",
        "        axes[1, 0].set_title('Signal vs Noise Over Time')\n",
        "        axes[1, 0].set_xlabel('Timestep')\n",
        "        axes[1, 0].set_ylabel('Coefficient')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True)\n",
        "        snr = self.alphas_cumprod / (1 - self.alphas_cumprod.clamp(max=0.9999))\n",
        "        axes[1, 1].plot(timesteps, snr.cpu().numpy())\n",
        "        axes[1, 1].set_title('Signal-to-Noise Ratio')\n",
        "        axes[1, 1].set_xlabel('Timestep')\n",
        "        axes[1, 1].set_ylabel('SNR')\n",
        "        axes[1, 1].set_yscale('log')\n",
        "        axes[1, 1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "class ForwardDiffusion:\n",
        "\n",
        "    def __init__(self, noise_schedule: NoiseSchedule):\n",
        "        self.schedule = noise_schedule\n",
        "        self.num_timesteps = noise_schedule.num_timesteps\n",
        "        self.device = noise_schedule.device\n",
        "\n",
        "    def add_noise(self,\n",
        "                  x_0: torch.Tensor,\n",
        "                  t: torch.Tensor,\n",
        "    ):\n",
        "\n",
        "        noise = torch.randn_like(x_0)\n",
        "        sqrt_alphas_cumprod_t = self.schedule.sqrt_alphas_cumprod[t]\n",
        "        sqrt_one_minus_alphas_cumprod_t = self.schedule.sqrt_one_minus_alphas_cumprod[t]\n",
        "        sqrt_alphas_cumprod_t = sqrt_alphas_cumprod_t.view(-1, 1)\n",
        "        sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod_t.view(-1, 1)\n",
        "        x_t = sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
        "\n",
        "        return x_t, noise\n",
        "\n",
        "    def sample_timesteps(self, batch_size: int) -> torch.Tensor:\n",
        "        return torch.randint(0, self.num_timesteps, (batch_size,), device=self.device)\n",
        "\n",
        "    def get_noise_level(self, t: int) -> float:\n",
        "        return self.schedule.sqrt_one_minus_alphas_cumprod[t].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W-WqpaHKg2d"
      },
      "source": [
        "**Convert Entire DataSet to latents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXVgLUg-KVUR",
        "outputId": "50c7007a-870b-41f9-b2e9-9a91a45be269"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda'\n",
        "autoencoder_path='/content/Output/AutoEncoder.pth'\n",
        "\n",
        "autoencoder = Autoencoder(\n",
        "    num_tile_types=13,\n",
        "    embedding_dim=32,\n",
        "    latent_dim=128,\n",
        "    patch_height=14,\n",
        "    patch_width=16\n",
        "  )\n",
        "\n",
        "ae_checkpoint = torch.load(autoencoder_path, map_location=device)\n",
        "autoencoder.load_state_dict(ae_checkpoint['model_state_dict'])\n",
        "autoencoder.to(device)\n",
        "autoencoder.eval()\n",
        "print(\" Autoencoder loaded\")\n",
        "for param in autoencoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\" Autoencoder loaded!\")\n",
        "\n",
        "print(f\"Loaded {len(all_patches)} patches\")\n",
        "print(\"num_scores:\", len(all_difficulties))\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "all_latents = []\n",
        "all_difficulties = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        patches, diffs = batch\n",
        "        patches = patches.to(device)\n",
        "        latents = autoencoder.encode(patches)\n",
        "\n",
        "        all_latents.append(latents.cpu())\n",
        "        all_difficulties.append(diffs.cpu())\n",
        "all_latents = torch.cat(all_latents, dim=0)\n",
        "all_difficulties = torch.cat(all_difficulties, 0)\n",
        "\n",
        "print(f\"Encoded latents shape: {all_latents.shape}\")\n",
        "print(f\"Latent dimension: {all_latents.shape[1]}\")\n",
        "print(f\"Difficulties shape: {all_difficulties.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQkA6SbCE1g0",
        "outputId": "e34e1434-9dd0-40f6-ff44-1776213baad7"
      },
      "outputs": [],
      "source": [
        "max(all_difficulties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_o4yeeRt_O6",
        "outputId": "756aebb4-4b7e-4284-ecd0-8f3e3b392ba6"
      },
      "outputs": [],
      "source": [
        "print(f\"latents: norm={all_latents.norm(dim=-1).mean():.2f}, std={all_latents.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oywn9H-GAR-",
        "outputId": "10c2f4bd-d9a0-48bc-fad5-45c6d5f7faa0"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING LATENT NORMALIZER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "normalizer = LatentNormalizer(target_norm=11.0)\n",
        "normalizer.fit(all_latents)\n",
        "latents_norm = normalizer.normalize(all_latents)\n",
        "print(f\"Normalized latents: norm={latents_norm.norm(dim=-1).mean():.2f}, std={latents_norm.std():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quuzOxanTUbE",
        "outputId": "5961796d-85a5-4217-cf44-c65e1608f512"
      },
      "outputs": [],
      "source": [
        "normalizer.save('Output/latent_normalizer.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBDJRo9UaCNy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Optional, Tuple, List\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class SinusoidalPositionalEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_dim: int, max_timesteps: int = 10000):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        position = torch.arange(max_timesteps).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.0) / embedding_dim))\n",
        "        pe = torch.zeros(max_timesteps, embedding_dim)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, timesteps: torch.Tensor) -> torch.Tensor:\n",
        "        return self.pe[timesteps]\n",
        "\n",
        "\n",
        "class FourierPlayabilityEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_dim: int, num_frequencies: int = 64):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_frequencies = num_frequencies\n",
        "\n",
        "        frequencies = torch.randn(num_frequencies) * 2.0\n",
        "        self.register_buffer('frequencies', frequencies)\n",
        "\n",
        "        fourier_dim = num_frequencies * 2\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(fourier_dim + 1, embedding_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(embedding_dim, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, playability: torch.Tensor) -> torch.Tensor:\n",
        "        if playability.dim() == 1:\n",
        "            playability = playability.unsqueeze(-1)\n",
        "\n",
        "        scaled = playability * 2 - 1\n",
        "\n",
        "        angles = scaled * self.frequencies.unsqueeze(0) * math.pi\n",
        "        fourier_features = torch.cat([\n",
        "            torch.sin(angles),\n",
        "            torch.cos(angles),\n",
        "            playability\n",
        "        ], dim=-1)\n",
        "\n",
        "        return self.projection(fourier_features)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim: int, time_emb_dim: int):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(nn.Linear(time_emb_dim, dim), nn.SiLU())\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.LayerNorm(dim),\n",
        "        )\n",
        "        self.activation = nn.SiLU()\n",
        "\n",
        "    def forward(self, x: torch.Tensor, time_emb: torch.Tensor) -> torch.Tensor:\n",
        "        time_proj = self.time_mlp(time_emb)\n",
        "        h = self.block(x + time_proj)\n",
        "        return self.activation(x + h)\n",
        "\n",
        "\n",
        "class MixingMLP(nn.Module):\n",
        "    def __init__(self, dim: int, hidden_scale: float = 1.0):\n",
        "        super().__init__()\n",
        "        mid = int(dim * hidden_scale)\n",
        "        mid = max(mid, dim)\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, mid), nn.SiLU(), nn.Linear(mid, dim))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return x + self.mlp(self.norm(x))\n",
        "\n",
        "\n",
        "class DiffusionUNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim: int = 128,\n",
        "        time_emb_dim: int = 256,\n",
        "        context_emb_dim: int = 128,\n",
        "        hidden_dims: list = [256, 512, 512],\n",
        "        num_res_blocks: int = 2,\n",
        "        cond_dropout: float = 0.15,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.time_emb_dim = time_emb_dim\n",
        "        self.context_emb_dim = context_emb_dim\n",
        "        self.prev_play_emb_dim = 64\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.num_res_blocks = num_res_blocks\n",
        "        self.cond_dropout = cond_dropout\n",
        "\n",
        "        self.output_scale = nn.Parameter(torch.tensor([1.0], dtype=torch.float32))\n",
        "\n",
        "        self.time_embedding = SinusoidalPositionalEmbedding(time_emb_dim)\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(time_emb_dim, time_emb_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim)\n",
        "        )\n",
        "\n",
        "        self.context_encoder_per = nn.Sequential(\n",
        "            nn.Linear(latent_dim, context_emb_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(context_emb_dim, time_emb_dim)\n",
        "        )\n",
        "\n",
        "        self.prev_playability_mlp = nn.Sequential(\n",
        "            nn.Linear(1, self.prev_play_emb_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(self.prev_play_emb_dim, time_emb_dim)\n",
        "        )\n",
        "\n",
        "        self.playability_embedding = FourierPlayabilityEmbedding(\n",
        "            embedding_dim=time_emb_dim,\n",
        "            num_frequencies=64\n",
        "        )\n",
        "        self.null_play_embedding = nn.Parameter(torch.randn(time_emb_dim) * 0.02)\n",
        "\n",
        "        self.input_proj = nn.Linear(latent_dim * 2, hidden_dims[0])\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList()\n",
        "        self.encoder_mixes = nn.ModuleList()\n",
        "        dims = [hidden_dims[0]] + hidden_dims\n",
        "        for i in range(len(hidden_dims)):\n",
        "            blocks = nn.ModuleList([ResidualBlock(dims[i], time_emb_dim) for _ in range(num_res_blocks)])\n",
        "            self.encoder_blocks.append(blocks)\n",
        "            self.encoder_mixes.append(MixingMLP(dims[i], hidden_scale=1.0))\n",
        "            if i < len(hidden_dims) - 1:\n",
        "                self.encoder_blocks.append(nn.ModuleList([nn.Linear(dims[i], dims[i + 1])]))\n",
        "\n",
        "        bottleneck_dim = hidden_dims[-1]\n",
        "        self.bottleneck = nn.ModuleList([ResidualBlock(bottleneck_dim, time_emb_dim) for _ in range(num_res_blocks)])\n",
        "        self.bottleneck_mix = MixingMLP(bottleneck_dim, hidden_scale=1.0)\n",
        "\n",
        "        self.decoder_blocks = nn.ModuleList()\n",
        "        self.decoder_mixes = nn.ModuleList()\n",
        "        self.skip_projections = nn.ModuleList()\n",
        "        reversed_dims = list(reversed(hidden_dims))\n",
        "        reversed_encoder_dims = [hidden_dims[0]] + hidden_dims\n",
        "        reversed_skip_dims = list(reversed(reversed_encoder_dims[:len(hidden_dims)]))\n",
        "\n",
        "        for i in range(len(reversed_dims)):\n",
        "            if i == 0:\n",
        "                blocks = nn.ModuleList([ResidualBlock(reversed_dims[i], time_emb_dim) for _ in range(num_res_blocks)])\n",
        "                self.decoder_blocks.append(blocks)\n",
        "                self.skip_projections.append(None)\n",
        "            else:\n",
        "                current_dim = reversed_dims[i - 1]\n",
        "                target_dim = reversed_dims[i]\n",
        "                skip_dim = reversed_skip_dims[i]\n",
        "                self.decoder_blocks.append(nn.Linear(current_dim, target_dim))\n",
        "                concat_dim = target_dim + skip_dim\n",
        "                self.skip_projections.append(nn.Linear(concat_dim, target_dim))\n",
        "                blocks = nn.ModuleList([ResidualBlock(target_dim, time_emb_dim) for _ in range(num_res_blocks)])\n",
        "                self.decoder_blocks.append(blocks)\n",
        "            self.decoder_mixes.append(MixingMLP(reversed_dims[i], hidden_scale=1.0))\n",
        "\n",
        "        self.output_proj = nn.Linear(hidden_dims[0], latent_dim)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"CFGDiffusionUNet Initialized\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"  Condition dropout: {cond_dropout*100:.0f}%\")\n",
        "        print(f\"  Latent dim: {latent_dim}\")\n",
        "        print(f\"  Parameters: {sum(p.numel() for p in self.parameters()):,}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        nn.init.xavier_uniform_(self.output_proj.weight, gain=1.0)\n",
        "        nn.init.zeros_(self.output_proj.bias)\n",
        "        for name, module in self.named_modules():\n",
        "            if isinstance(module, nn.Linear) and 'mlp' in name.lower():\n",
        "                nn.init.xavier_uniform_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        timesteps: torch.Tensor,\n",
        "        previous_latents: Optional[torch.Tensor] = None,\n",
        "        previous_difficulties: Optional[torch.Tensor] = None,\n",
        "        target_playability: Optional[torch.Tensor] = None,\n",
        "    ) -> torch.Tensor:\n",
        "\n",
        "        batch = x.shape[0]\n",
        "        device = x.device\n",
        "        dtype = x.dtype\n",
        "\n",
        "        x = x.to(device=device, dtype=dtype)\n",
        "        if timesteps.dtype != torch.long:\n",
        "            timesteps = timesteps.long()\n",
        "        timesteps = timesteps.to(device=device)\n",
        "\n",
        "        t_emb = self.time_embedding(timesteps)\n",
        "        t_emb = self.time_mlp(t_emb)\n",
        "\n",
        "        if previous_latents is None:\n",
        "            previous_latents = torch.zeros((batch, 1, self.latent_dim), device=device, dtype=dtype)\n",
        "            inferred_k = 1\n",
        "            prev_flat = previous_latents.reshape(-1, self.latent_dim)\n",
        "        else:\n",
        "            previous_latents = previous_latents.to(device=device, dtype=dtype).contiguous()\n",
        "            if previous_latents.dim() == 3:\n",
        "                prev_flat = previous_latents.reshape(-1, self.latent_dim)\n",
        "                inferred_total = prev_flat.shape[0]\n",
        "                if inferred_total % batch != 0:\n",
        "                    raise RuntimeError('previous_latents flattened count not divisible by batch')\n",
        "                inferred_k = inferred_total // batch\n",
        "            elif previous_latents.dim() == 2:\n",
        "                prev_flat = previous_latents\n",
        "                inferred_total = prev_flat.shape[0]\n",
        "                if inferred_total % batch != 0:\n",
        "                    raise RuntimeError('previous_latents flattened length not divisible by batch')\n",
        "                inferred_k = inferred_total // batch\n",
        "            else:\n",
        "                raise ValueError('previous_latents must be 2D or 3D')\n",
        "\n",
        "        prev_enc = self.context_encoder_per(prev_flat)\n",
        "        prev_enc = prev_enc.reshape(batch, inferred_k, -1)\n",
        "        k = inferred_k\n",
        "\n",
        "        if previous_difficulties is None:\n",
        "            previous_difficulties = torch.zeros((batch, k), device=device, dtype=dtype)\n",
        "        else:\n",
        "            previous_difficulties = previous_difficulties.to(device=device, dtype=dtype)\n",
        "            if previous_difficulties.dim() == 2:\n",
        "                if previous_difficulties.shape[0] != batch or previous_difficulties.shape[1] != k:\n",
        "                    if previous_difficulties.numel() == batch * k:\n",
        "                        previous_difficulties = previous_difficulties.reshape(batch, k)\n",
        "                    else:\n",
        "                        raise ValueError('previous_difficulties shape incompatible')\n",
        "            elif previous_difficulties.dim() == 1:\n",
        "                n = previous_difficulties.numel()\n",
        "                if n == k:\n",
        "                    previous_difficulties = previous_difficulties.unsqueeze(0).repeat(batch, 1)\n",
        "                elif n == batch * k:\n",
        "                    previous_difficulties = previous_difficulties.reshape(batch, k)\n",
        "                else:\n",
        "                    raise ValueError('previous_difficulties length incompatible')\n",
        "\n",
        "        prev_play_flat = previous_difficulties.reshape(batch * k, 1)\n",
        "        prev_play_enc = self.prev_playability_mlp(prev_play_flat)\n",
        "        prev_play_enc = prev_play_enc.reshape(batch, k, -1)\n",
        "\n",
        "        per_prev = prev_enc + prev_play_enc\n",
        "        ctx_emb = per_prev.mean(dim=1)\n",
        "\n",
        "        if target_playability is None:\n",
        "            play_emb = self.null_play_embedding.unsqueeze(0).expand(batch, -1)\n",
        "        else:\n",
        "            target_playability = target_playability.to(device=device, dtype=dtype)\n",
        "            if target_playability.dim() == 0:\n",
        "                target_playability = target_playability.unsqueeze(0)\n",
        "            if target_playability.dim() == 1:\n",
        "                target_playability = target_playability.view(-1, 1)\n",
        "\n",
        "            play_emb = self.playability_embedding(target_playability)\n",
        "\n",
        "            if self.training and self.cond_dropout > 0:\n",
        "                drop_mask = (torch.rand(batch, device=device) < self.cond_dropout).unsqueeze(1)\n",
        "                null_emb = self.null_play_embedding.unsqueeze(0).expand(batch, -1)\n",
        "                play_emb = torch.where(drop_mask, null_emb, play_emb)\n",
        "\n",
        "        if previous_latents.dim() == 2:\n",
        "            prev_lat_for_mean = prev_flat.reshape(batch, k, self.latent_dim)\n",
        "        else:\n",
        "            prev_lat_for_mean = previous_latents.reshape(batch, k, self.latent_dim)\n",
        "        prev_lat_mean = prev_lat_for_mean.mean(dim=1)\n",
        "\n",
        "        h = torch.cat([x, prev_lat_mean], dim=-1)\n",
        "        h = self.input_proj(h)\n",
        "\n",
        "        combined_emb = t_emb + ctx_emb + play_emb\n",
        "\n",
        "        skip_connections = []\n",
        "        block_idx = 0\n",
        "        for i in range(len(self.hidden_dims)):\n",
        "            for res_block in self.encoder_blocks[block_idx]:\n",
        "                h = res_block(h, combined_emb)\n",
        "            block_idx += 1\n",
        "            h = self.encoder_mixes[i](h)\n",
        "            skip_connections.append(h)\n",
        "            if i < len(self.hidden_dims) - 1:\n",
        "                for down_layer in self.encoder_blocks[block_idx]:\n",
        "                    h = down_layer(h)\n",
        "                block_idx += 1\n",
        "\n",
        "        for bottleneck_block in self.bottleneck:\n",
        "            h = bottleneck_block(h, combined_emb)\n",
        "        h = self.bottleneck_mix(h)\n",
        "\n",
        "        skip_connections = list(reversed(skip_connections))\n",
        "        decoder_block_idx = 0\n",
        "        for i in range(len(self.hidden_dims)):\n",
        "            if i == 0:\n",
        "                for res_block in self.decoder_blocks[decoder_block_idx]:\n",
        "                    h = res_block(h, combined_emb)\n",
        "                decoder_block_idx += 1\n",
        "            else:\n",
        "                h = self.decoder_blocks[decoder_block_idx](h)\n",
        "                decoder_block_idx += 1\n",
        "                skip = skip_connections[i]\n",
        "                h = torch.cat([h, skip], dim=-1)\n",
        "                h = self.skip_projections[i](h)\n",
        "                for res_block in self.decoder_blocks[decoder_block_idx]:\n",
        "                    h = res_block(h, combined_emb)\n",
        "                decoder_block_idx += 1\n",
        "            h = self.decoder_mixes[i](h)\n",
        "\n",
        "        noise_pred = self.output_proj(h)\n",
        "        scale = self.output_scale.clamp(min=0.1, max=10.0)\n",
        "        noise_pred = noise_pred * scale\n",
        "\n",
        "        return noise_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6TB5S60dtmm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from typing import Optional, Sequence\n",
        "\n",
        "\n",
        "class AutoregressivePatchDatasetCreator(torch.utils.data.Dataset):\n",
        "    def __init__(self,\n",
        "                 latents: torch.Tensor,\n",
        "                 difficulties: Sequence,\n",
        "                 num_prev: int = 10,\n",
        "                 level_ids: Optional[Sequence] = None):\n",
        "        super().__init__()\n",
        "\n",
        "        assert latents.dim() == 2\n",
        "        num_patches = latents.shape[0]\n",
        "\n",
        "        assert len(difficulties) == num_patches\n",
        "        if level_ids is not None:\n",
        "            assert len(level_ids) == num_patches\n",
        "\n",
        "        self.latents = latents\n",
        "        self.difficulties = torch.as_tensor(difficulties, dtype=latents.dtype)\n",
        "        self.num_prev = int(num_prev)\n",
        "        self.level_ids = torch.as_tensor(level_ids) if level_ids is not None else None\n",
        "\n",
        "        self.num_patches = num_patches\n",
        "        self.latent_dim = latents.shape[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_patches\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        if idx < 0 or idx >= self.num_patches:\n",
        "            raise IndexError(f\"Index {idx} out of range for dataset of size {self.num_patches}\")\n",
        "\n",
        "        device = self.latents.device\n",
        "        dtype = self.latents.dtype\n",
        "        k = self.num_prev\n",
        "\n",
        "        current_latent = self.latents[idx]\n",
        "        current_playability = self.difficulties[idx].unsqueeze(0)\n",
        "        zero_latent = torch.zeros(self.latent_dim, dtype=dtype, device=device)\n",
        "        zero_play = torch.zeros(1, dtype=dtype, device=device)\n",
        "\n",
        "        prev_latents = []\n",
        "        prev_difficulties = []\n",
        "\n",
        "        for j in range(1, k + 1):\n",
        "            prev_idx = idx - j\n",
        "            if prev_idx < 0:\n",
        "                prev_latents.append(zero_latent)\n",
        "                prev_difficulties.append(zero_play)\n",
        "                continue\n",
        "            if self.level_ids is not None:\n",
        "                if self.level_ids[prev_idx].item() != self.level_ids[idx].item():\n",
        "                    prev_latents.append(zero_latent)\n",
        "                    prev_difficulties.append(zero_play)\n",
        "                    continue\n",
        "            prev_latents.append(self.latents[prev_idx].to(device))\n",
        "            prev_difficulties.append(self.difficulties[prev_idx].unsqueeze(0).to(device))\n",
        "        prev_latents = torch.stack(prev_latents, dim=0)\n",
        "        prev_difficulties = torch.cat(prev_difficulties, dim=0).view(k)\n",
        "        current_latent = current_latent.to(device)\n",
        "        current_playability = current_playability.to(device)\n",
        "\n",
        "        return current_latent, prev_latents, current_playability, prev_difficulties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWVfkvO9t9M4",
        "outputId": "aad5a48d-9f1a-45d3-91a9-f5d9942624eb"
      },
      "outputs": [],
      "source": [
        "all_difficulties.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOKHpzrQg5hl",
        "outputId": "31fa2d26-6f46-4afb-dcb5-51a92fa114a3"
      },
      "outputs": [],
      "source": [
        "metadata[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZlPOLCXpb3m",
        "outputId": "0b9334f0-199c-47a1-8632-8e7105ce2a91"
      },
      "outputs": [],
      "source": [
        "all_latents.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFQxKYFFsGmW"
      },
      "outputs": [],
      "source": [
        "class DiffusionTrainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: DiffusionUNet,\n",
        "        noise_schedule,\n",
        "        forward_diffusion,\n",
        "        learning_rate: float = 1e-4,\n",
        "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ):\n",
        "        self.unet = unet.to(device)\n",
        "        self.schedule = noise_schedule\n",
        "        self.forward = forward_diffusion\n",
        "        self.device = device\n",
        "\n",
        "        for name in [\"sqrt_alphas_cumprod\", \"sqrt_one_minus_alphas_cumprod\",\n",
        "                     \"posterior_variance\", \"alphas\", \"betas\", \"alphas_cumprod\"]:\n",
        "            val = getattr(self.schedule, name, None)\n",
        "            if isinstance(val, torch.Tensor):\n",
        "                setattr(self.schedule, name, val.to(device))\n",
        "\n",
        "        self.optimizer = optim.AdamW(self.unet.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.optimizer, T_max=200, eta_min=learning_rate * 0.01\n",
        "        )\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.epoch_losses = []\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"CFG Trainer Initialized\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"  Device: {device}\")\n",
        "        print(f\"  Condition dropout: {unet.cond_dropout*100:.0f}%\")\n",
        "        print(f\"  NOTE: Target playability is now an INPUT condition\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        \"\"\"Single training step.\"\"\"\n",
        "        self.unet.train()\n",
        "\n",
        "        current_latent, prev_latents, curr_play, prev_play = batch_data\n",
        "        current_latent = current_latent.to(self.device).float()\n",
        "        prev_latents = prev_latents.to(self.device).float()\n",
        "        curr_play = curr_play.to(self.device).float()\n",
        "        prev_play = prev_play.to(self.device).float()\n",
        "\n",
        "        batch_size = current_latent.shape[0]\n",
        "        timesteps = self.forward.sample_timesteps(batch_size).to(self.device).long()\n",
        "\n",
        "        noisy_latent, noise = self.forward.add_noise(current_latent, timesteps)\n",
        "\n",
        "        if curr_play.dim() == 2:\n",
        "            target_play = curr_play.squeeze(1)\n",
        "        else:\n",
        "            target_play = curr_play\n",
        "\n",
        "        predicted_noise = self.unet(\n",
        "            x=noisy_latent,\n",
        "            timesteps=timesteps,\n",
        "            previous_latents=prev_latents,\n",
        "            previous_difficulties=prev_play,\n",
        "            target_playability=target_play\n",
        "        )\n",
        "\n",
        "        loss = self.criterion(predicted_noise, noise)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.unet.parameters(), max_norm=1.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return {'total': loss.item(), 'noise': loss.item()}\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.unet.eval()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_data in val_loader:\n",
        "                current_latent, prev_latents, curr_play, prev_play = batch_data\n",
        "                current_latent = current_latent.to(self.device).float()\n",
        "                prev_latents = prev_latents.to(self.device).float()\n",
        "                curr_play = curr_play.to(self.device).float()\n",
        "                prev_play = prev_play.to(self.device).float()\n",
        "\n",
        "                batch_size = current_latent.shape[0]\n",
        "                timesteps = self.forward.sample_timesteps(batch_size).to(self.device).long()\n",
        "                noisy_latents, noise = self.forward.add_noise(current_latent, timesteps)\n",
        "\n",
        "                if curr_play.dim() == 2:\n",
        "                    target_play = curr_play.squeeze(1)\n",
        "                else:\n",
        "                    target_play = curr_play\n",
        "\n",
        "                predicted_noise = self.unet(\n",
        "                    x=noisy_latents,\n",
        "                    timesteps=timesteps,\n",
        "                    previous_latents=prev_latents,\n",
        "                    previous_difficulties=prev_play,\n",
        "                    target_playability=target_play\n",
        "                )\n",
        "\n",
        "                loss = self.criterion(predicted_noise, noise)\n",
        "                total_loss += loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / max(1, num_batches)\n",
        "        return avg_loss\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        train_loader,\n",
        "        val_loader=None,\n",
        "        num_epochs=500,\n",
        "        save_interval=50,\n",
        "        save_path='cfg_diffusion.pth'\n",
        "    ):\n",
        "        print(\"=\" * 70)\n",
        "        print(\"TRAINING CFG DIFFUSION MODEL\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(f\"Parameters: {sum(p.numel() for p in self.unet.parameters()):,}\")\n",
        "        print(f\"Epochs: {num_epochs}\")\n",
        "\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.optimizer, T_max=num_epochs, eta_min=self.optimizer.param_groups[0]['lr'] * 0.01\n",
        "        )\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_loss = 0\n",
        "            self.unet.train()\n",
        "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            for batch_data in progress_bar:\n",
        "                losses = self.train_step(batch_data)\n",
        "                epoch_loss += losses['total']\n",
        "                progress_bar.set_postfix({\n",
        "                    'loss': f\"{losses['total']:.4f}\",\n",
        "                    'lr': f\"{self.optimizer.param_groups[0]['lr']:.6f}\"\n",
        "                })\n",
        "\n",
        "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "            self.epoch_losses.append(avg_epoch_loss)\n",
        "            self.scheduler.step()\n",
        "\n",
        "            if val_loader is not None:\n",
        "                val_loss = self.validate(val_loader)\n",
        "                self.val_losses.append(val_loss)\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    self.save_checkpoint(save_path.replace('.pth', '_best.pth'))\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs} | Train: {avg_epoch_loss:.4f} | Val: {val_loss:.4f}\")\n",
        "            else:\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs} | Train: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "            if (epoch + 1) % save_interval == 0:\n",
        "                self.save_checkpoint(save_path.replace('.pth', f'_epoch{epoch+1}.pth'))\n",
        "\n",
        "        self.save_checkpoint(save_path)\n",
        "        print(f\"\\n Training complete! Best val loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    def save_checkpoint(self, path):\n",
        "        torch.save({\n",
        "            'unet_state_dict': self.unet.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'epoch_losses': self.epoch_losses,\n",
        "            'val_losses': self.val_losses,\n",
        "        }, path)\n",
        "\n",
        "    def plot_losses(self, save_path=None):\n",
        "        plt.figure(figsize=(8,5))\n",
        "        plt.plot(self.epoch_losses, label='Train Loss')\n",
        "        if self.val_losses:\n",
        "            plt.plot(self.val_losses, label='Val Loss')\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training Progress\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA2jW4Y0flLz"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "import itertools\n",
        "\n",
        "def train_conditional_diffusion_model(\n",
        "    latents: np.ndarray,\n",
        "    metadata: List[Dict],\n",
        "    autoencoder_path: str,\n",
        "    save_path: str = '/content/Output/conditional_diffusion.pth',\n",
        "    num_epochs: int = 500,\n",
        "    batch_size: int = 16):\n",
        "\n",
        "\n",
        "    device = 'cuda'\n",
        "\n",
        "\n",
        "    autoencoder = Autoencoder(\n",
        "        num_tile_types=13,\n",
        "        embedding_dim=32,\n",
        "        latent_dim=128,\n",
        "        patch_height=14,\n",
        "        patch_width=16\n",
        "    )\n",
        "\n",
        "    ae_checkpoint = torch.load(autoencoder_path, map_location=device)\n",
        "    autoencoder.load_state_dict(ae_checkpoint['model_state_dict'])\n",
        "    autoencoder.to(device)\n",
        "    autoencoder.eval()\n",
        "    print(\" Autoencoder loaded\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 4: Creating Training Dataset\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(f'scores min/max: {min(all_difficulties)}/{max(all_difficulties)}')\n",
        "    dataset = AutoregressivePatchDatasetCreator(latents, all_difficulties)\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    batch = next(iter(train_loader))\n",
        "    latents_check = batch[0]\n",
        "    print(f\"Latent norm: {latents_check.norm(dim=-1).mean():.4f}\")\n",
        "    print(f\"Latent std: {latents_check.std():.4f}\")\n",
        "\n",
        "    print(f\"  Train: {train_size} samples\")\n",
        "    print(f\"  Val: {val_size} samples\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 5: Creating Conditional U-Net\")\n",
        "    print(\"=\"*70)\n",
        "    unet = DiffusionUNet(\n",
        "        latent_dim=128,\n",
        "        time_emb_dim=256,\n",
        "        context_emb_dim=128,\n",
        "        hidden_dims=[256, 512, 512],\n",
        "        num_res_blocks=2,\n",
        "    ).to(device)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"MODEL INITIALIZATION CHECK\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Output scale initial value: {unet.output_scale.item()}\")\n",
        "    print(f\"Output scale requires_grad: {unet.output_scale.requires_grad}\")\n",
        "    print(f\"Output projection type: {type(unet.output_proj)}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "    num_params = sum(p.numel() for p in unet.parameters())\n",
        "    print(f\" Model created: {num_params:,} parameters\")\n",
        "    schedule = NoiseSchedule(\n",
        "        num_timesteps=500,\n",
        "        schedule_type='linear',\n",
        "        device=device,\n",
        "    )\n",
        "    forward = ForwardDiffusion(schedule)\n",
        "\n",
        "    trainer = DiffusionTrainer(\n",
        "        unet=unet,\n",
        "        noise_schedule=schedule,\n",
        "        forward_diffusion=forward,\n",
        "        learning_rate=5e-4,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 7: Training\")\n",
        "    print(\"=\"*70)\n",
        "    trainer.train(\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=num_epochs,\n",
        "        save_interval=300,\n",
        "        save_path=save_path\n",
        "    )\n",
        "\n",
        "    trainer.plot_losses(save_path.replace('.pth', '_losses.png'))\n",
        "\n",
        "    return trainer, unet, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqiAjMMTwJYy",
        "outputId": "b35b8a85-8ff5-49a4-9ba1-0172ab5b0a99"
      },
      "outputs": [],
      "source": [
        "all_latents.dim()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0UnOnGs1etF"
      },
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: DiffusionUNet,\n",
        "        noise_schedule,\n",
        "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ):\n",
        "        self.unet = unet.to(device)\n",
        "        self.schedule = noise_schedule\n",
        "        self.device = device\n",
        "        self.unet.eval()\n",
        "\n",
        "        # Move schedule tensors to device\n",
        "        for name in [\"sqrt_alphas_cumprod\", \"sqrt_one_minus_alphas_cumprod\",\n",
        "                     \"posterior_variance\", \"alphas\", \"betas\", \"alphas_cumprod\"]:\n",
        "            val = getattr(self.schedule, name, None)\n",
        "            if isinstance(val, torch.Tensor):\n",
        "                setattr(self.schedule, name, val.to(device))\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"CFG Sampler Initialized\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"  Device: {device}\")\n",
        "        print(f\"  Timesteps: {self.schedule.num_timesteps}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _denoise_step(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        t_batch: torch.Tensor,\n",
        "        predicted_noise: torch.Tensor,\n",
        "        temperature: float\n",
        "    ) -> torch.Tensor:\n",
        "        device = x.device\n",
        "        dtype = x.dtype\n",
        "\n",
        "        alpha_t = self.schedule.alphas[t_batch].to(device=device, dtype=dtype).view(-1, 1)\n",
        "        beta_t = self.schedule.betas[t_batch].to(device=device, dtype=dtype).view(-1, 1)\n",
        "        alpha_cumprod_t = self.schedule.alphas_cumprod[t_batch].to(device=device, dtype=dtype).view(-1, 1)\n",
        "\n",
        "        eps = 1e-8\n",
        "        sqrt_alpha_t = torch.sqrt(alpha_t.clamp(min=eps))\n",
        "        sqrt_one_minus_alpha_cumprod_t = torch.sqrt((1.0 - alpha_cumprod_t).clamp(min=eps))\n",
        "\n",
        "        mean = (1.0 / sqrt_alpha_t) * (x - (beta_t / sqrt_one_minus_alpha_cumprod_t) * predicted_noise)\n",
        "\n",
        "        if t_batch[0] > 0:\n",
        "            variance = beta_t\n",
        "            std = torch.sqrt(variance.clamp(min=eps))\n",
        "            noise = torch.randn_like(x)\n",
        "            x_prev = mean + std * temperature * noise\n",
        "        else:\n",
        "            x_prev = mean\n",
        "\n",
        "        return x_prev\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample_single_patch(\n",
        "        self,\n",
        "        normalizer,\n",
        "        previous_latent: Optional[torch.Tensor],\n",
        "        target_playability: float,\n",
        "        previous_difficulties: Optional[list] = None,\n",
        "        temperature: float = 0.9,\n",
        "        guidance_scale: float = 3.0,\n",
        "        show_progress: bool = False\n",
        "    ) -> torch.Tensor:\n",
        "\n",
        "        device = self.device\n",
        "        latent_dim = self.unet.latent_dim\n",
        "\n",
        "        x = torch.randn(1, latent_dim, device=device) * temperature\n",
        "        x = x / (x.norm(dim=-1, keepdim=True) + 1e-12) * normalizer.target_norm\n",
        "\n",
        "        target_play_tensor = torch.tensor([target_playability], device=device, dtype=torch.float32)\n",
        "\n",
        "        if previous_latent is None:\n",
        "            prev_lat = torch.zeros((1, 1, latent_dim), device=device)\n",
        "            prev_play = torch.zeros((1, 1), device=device)\n",
        "        else:\n",
        "            if previous_latent.dim() == 1:\n",
        "                previous_latent = previous_latent.unsqueeze(0)\n",
        "            prev_lat = previous_latent.unsqueeze(0).to(device)\n",
        "            if previous_difficulties is None:\n",
        "                prev_play = torch.zeros((1, prev_lat.shape[1]), device=device)\n",
        "            else:\n",
        "                prev_play = torch.tensor(previous_difficulties, device=device).unsqueeze(0)\n",
        "\n",
        "        timesteps = range(self.schedule.num_timesteps - 1, -1, -1)\n",
        "        if show_progress:\n",
        "            timesteps = tqdm(timesteps, desc=f\"Sampling (CFG scale={guidance_scale})\")\n",
        "\n",
        "        self.unet.eval()\n",
        "        for t in timesteps:\n",
        "            t_batch = torch.tensor([t], device=device, dtype=torch.long)\n",
        "\n",
        "            noise_cond = self.unet(\n",
        "                x=x,\n",
        "                timesteps=t_batch,\n",
        "                previous_latents=prev_lat,\n",
        "                previous_difficulties=prev_play,\n",
        "                target_playability=target_play_tensor\n",
        "            )\n",
        "\n",
        "            noise_uncond = self.unet(\n",
        "                x=x,\n",
        "                timesteps=t_batch,\n",
        "                previous_latents=prev_lat,\n",
        "                previous_difficulties=prev_play,\n",
        "                target_playability=None\n",
        "            )\n",
        "\n",
        "            noise_guided = noise_uncond + guidance_scale * (noise_cond - noise_uncond)\n",
        "\n",
        "            x = self._denoise_step(x, t_batch, noise_guided, temperature)\n",
        "\n",
        "            if torch.isnan(x).any() or torch.isinf(x).any():\n",
        "                x = torch.nan_to_num(x, nan=0.0, posinf=1e8, neginf=-1e8)\n",
        "\n",
        "        return x.squeeze(0)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample_level(\n",
        "        self,\n",
        "        normalizer,\n",
        "        num_patches: int,\n",
        "        difficulty_target: float = 0.5,\n",
        "        temperature: float = 0.9,\n",
        "        guidance_scale: float = 3.0,\n",
        "        show_progress: bool = True\n",
        "    ) -> torch.Tensor:\n",
        "        generated = []\n",
        "        prev_buffer = []\n",
        "        prev_play_buffer = []\n",
        "\n",
        "        if isinstance(difficulty_target, (list, tuple)):\n",
        "            playability_schedule = [float(p) for p in difficulty_target]\n",
        "        else:\n",
        "\n",
        "            scalar_target = float(difficulty_target)\n",
        "            scalar_target = max(0.0, min(1.0, scalar_target))\n",
        "            if num_patches == 1:\n",
        "                playability_schedule = [scalar_target]\n",
        "            else:\n",
        "                power = 2.0\n",
        "                t = torch.linspace(0.0, 1.0, steps=num_patches)\n",
        "                curved = t ** power\n",
        "                playability_schedule = (curved * scalar_target).tolist()\n",
        "                print(f\"  Playability ramp (power={power}): {playability_schedule[0]:.2f}  {playability_schedule[-1]:.2f}\")\n",
        "\n",
        "\n",
        "        iterator = range(num_patches)\n",
        "        if show_progress:\n",
        "            iterator = tqdm(iterator, desc=\"Generating level (CFG)\")\n",
        "\n",
        "        for i in iterator:\n",
        "            if len(prev_buffer) == 0:\n",
        "                prev_lat = None\n",
        "                prev_play = None\n",
        "            else:\n",
        "                prev_lat = torch.stack(prev_buffer, dim=0).to(self.device)\n",
        "                prev_play = prev_play_buffer.copy()\n",
        "\n",
        "            latent = self.sample_single_patch(\n",
        "                normalizer=normalizer,\n",
        "                previous_latent=prev_lat,\n",
        "                target_playability=playability_schedule[i],\n",
        "                previous_difficulties=prev_play,\n",
        "                temperature=temperature,\n",
        "                guidance_scale=guidance_scale,\n",
        "                show_progress=False\n",
        "            )\n",
        "\n",
        "            generated.append(latent)\n",
        "            prev_buffer.append(latent.cpu())\n",
        "            prev_play_buffer.append(playability_schedule[i])\n",
        "\n",
        "        result = torch.stack(generated, dim=0)\n",
        "\n",
        "        if show_progress:\n",
        "            print(f\"\\n Generated {num_patches} patches with CFG (scale={guidance_scale})\")\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fLTxqlpzjph"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from typing import Optional, List, Dict, Tuple\n",
        "\n",
        "class PatchStitcher:\n",
        "    def __init__(self,\n",
        "                 patch_height: int = 14,\n",
        "                 patch_width: int = 16,\n",
        "                 stride: int = 4):\n",
        "\n",
        "        self.patch_height = patch_height\n",
        "        self.patch_width = patch_width\n",
        "        self.stride = stride\n",
        "\n",
        "    def stitch_patches_to_level(self,\n",
        "                            patches: np.ndarray,\n",
        "                            target_width: int = None,\n",
        "                            ) -> np.ndarray:\n",
        "        num_patches = len(patches)\n",
        "        first_patch = patches[0]\n",
        "        ph, pw = first_patch.shape\n",
        "\n",
        "        if ph != self.patch_height or pw != self.patch_width:\n",
        "            self.patch_height = ph\n",
        "            self.patch_width = pw\n",
        "\n",
        "        target_width = (num_patches - 1) * self.stride + pw\n",
        "\n",
        "        level = np.zeros((ph, target_width), dtype=np.int32)\n",
        "\n",
        "        for i, patch in enumerate(patches):\n",
        "            if patch.ndim != 2:\n",
        "                raise ValueError(f\"Each patch must be 2D. Got ndim={patch.ndim} at index {i}.\")\n",
        "\n",
        "            ph_i, pw_i = patch.shape\n",
        "            if ph_i != ph:\n",
        "                if ph_i > ph:\n",
        "                    patch = patch[:ph, :]\n",
        "                else:\n",
        "                    patch = np.pad(patch, ((0, ph - ph_i), (0, 0)), mode='constant', constant_values=0)\n",
        "\n",
        "            x_start = i * self.stride\n",
        "\n",
        "            if i == num_patches - 1:\n",
        "                x_end = x_start + pw_i\n",
        "                patch_slice = patch\n",
        "            else:\n",
        "                x_end = x_start + self.stride\n",
        "                patch_slice = patch[:, :self.stride]\n",
        "            if x_end > target_width:\n",
        "                overflow = x_end - target_width\n",
        "                x_end = target_width\n",
        "                patch_slice = patch_slice[:, :-overflow]\n",
        "            level[:, x_start:x_end] = patch_slice\n",
        "\n",
        "        return level\n",
        "\n",
        "    def compare_cfg_difficulty(self,\n",
        "                              sampler,\n",
        "                              normalizer,\n",
        "                              autoencoder,\n",
        "                              parser,\n",
        "                              difficulty_evaluator,\n",
        "                              guidance_scales: List[float] = [0.0, 1.0, 2.0, 3.0, 5.0, 7.0],\n",
        "                              num_patches: int = 10,\n",
        "                              target_playability: float = 0.8,\n",
        "                              temperature: float = 0.5,\n",
        "                              device: str = 'cuda',\n",
        "                              save_path: Optional[str] = None) -> Dict:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"CFG CONDITIONAL VS UNCONDITIONAL COMPARISON\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Target Playability: {target_playability}\")\n",
        "        print(f\"Guidance Scales: {guidance_scales}\")\n",
        "        print(f\"Patches per condition: {num_patches}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        print(\"Step 1: Generating UNCONDITIONAL baseline (scale = 0.0)...\")\n",
        "        latents_uncond = sampler.sample_level(\n",
        "            num_patches=num_patches,\n",
        "            normalizer=normalizer,\n",
        "            difficulty_target=target_playability,\n",
        "            temperature=temperature,\n",
        "            guidance_scale=0.0,\n",
        "            show_progress=False\n",
        "        )\n",
        "        print(f\" Unconditional generation complete: {latents_uncond.shape}\")\n",
        "\n",
        "        latents_denorm = normalizer.denormalize(latents_uncond)\n",
        "        with torch.no_grad():\n",
        "            latents_denorm = latents_denorm.to(device)\n",
        "            decoded_logits = autoencoder.decoder(latents_denorm)\n",
        "\n",
        "            if decoded_logits.dim() == 4:\n",
        "                patches = torch.argmax(decoded_logits, dim=1)\n",
        "            elif decoded_logits.dim() == 3:\n",
        "                patches = decoded_logits.long()\n",
        "            elif decoded_logits.dim() == 5:\n",
        "                decoded_logits = decoded_logits.squeeze(1)\n",
        "                patches = torch.argmax(decoded_logits, dim=1)\n",
        "            else:\n",
        "                patches = torch.argmax(decoded_logits, dim=-1)\n",
        "\n",
        "        patches_np_uncond = patches.cpu().numpy()\n",
        "        print(f\" Decoded to patches: {patches_np_uncond.shape}\")\n",
        "\n",
        "        uncond_evals = difficulty_evaluator.evaluate_patches_batch(patches_np_uncond)\n",
        "        uncond_difficulties = [e['scores']['difficulty_score'] for e in uncond_evals]\n",
        "        uncond_enemies = [e['counts']['enemies'] for e in uncond_evals]\n",
        "        uncond_cannons = [e['counts']['cannons'] for e in uncond_evals]\n",
        "\n",
        "        uncond_mean_diff = np.mean(uncond_difficulties)\n",
        "        uncond_std_diff = np.std(uncond_difficulties)\n",
        "        print(f\" Unconditional difficulty: {uncond_mean_diff:.3f}  {uncond_std_diff:.3f}\")\n",
        "        print(f\"  Enemies: {np.mean(uncond_enemies):.2f}, Cannons: {np.mean(uncond_cannons):.2f}\\n\")\n",
        "\n",
        "        print(\"Step 2: Generating CONDITIONAL with different guidance scales...\\n\")\n",
        "\n",
        "        results = {\n",
        "            'unconditional': {\n",
        "                'mean_difficulty': uncond_mean_diff,\n",
        "                'std_difficulty': uncond_std_diff,\n",
        "                'mean_enemies': np.mean(uncond_enemies),\n",
        "                'mean_cannons': np.mean(uncond_cannons),\n",
        "                'difficulties': uncond_difficulties\n",
        "            },\n",
        "            'conditional_by_scale': {},\n",
        "            'comparison_table': []\n",
        "        }\n",
        "\n",
        "        conditional_scales = [s for s in guidance_scales if s > 0.0]\n",
        "\n",
        "        for scale in conditional_scales:\n",
        "            print(f\"  Testing scale = {scale}...\")\n",
        "\n",
        "            latents_cond = sampler.sample_level(\n",
        "                num_patches=num_patches,\n",
        "                normalizer=normalizer,\n",
        "                difficulty_target=target_playability,\n",
        "                temperature=temperature,\n",
        "                guidance_scale=scale,\n",
        "                show_progress=False\n",
        "            )\n",
        "\n",
        "            latents_denorm = normalizer.denormalize(latents_cond)\n",
        "            with torch.no_grad():\n",
        "                latents_denorm = latents_denorm.to(device)\n",
        "                decoded_logits = autoencoder.decoder(latents_denorm)\n",
        "\n",
        "                if decoded_logits.dim() == 4:\n",
        "                    patches = torch.argmax(decoded_logits, dim=1)\n",
        "                elif decoded_logits.dim() == 3:\n",
        "                    patches = decoded_logits.long()\n",
        "                elif decoded_logits.dim() == 5:\n",
        "                    decoded_logits = decoded_logits.squeeze(1)\n",
        "                    patches = torch.argmax(decoded_logits, dim=1)\n",
        "                else:\n",
        "                    patches = torch.argmax(decoded_logits, dim=-1)\n",
        "\n",
        "            patches_np_cond = patches.cpu().numpy()\n",
        "\n",
        "            cond_evals = difficulty_evaluator.evaluate_patches_batch(patches_np_cond)\n",
        "            cond_difficulties = [e['scores']['difficulty_score'] for e in cond_evals]\n",
        "            cond_enemies = [e['counts']['enemies'] for e in cond_evals]\n",
        "            cond_cannons = [e['counts']['cannons'] for e in cond_evals]\n",
        "\n",
        "            cond_mean_diff = np.mean(cond_difficulties)\n",
        "            cond_std_diff = np.std(cond_difficulties)\n",
        "\n",
        "            diff = cond_mean_diff - uncond_mean_diff\n",
        "\n",
        "            results['conditional_by_scale'][scale] = {\n",
        "                'mean_difficulty': cond_mean_diff,\n",
        "                'std_difficulty': cond_std_diff,\n",
        "                'mean_enemies': np.mean(cond_enemies),\n",
        "                'mean_cannons': np.mean(cond_cannons),\n",
        "                'difficulties': cond_difficulties\n",
        "            }\n",
        "\n",
        "            print(f\"     Difficulty: {cond_mean_diff:.3f}  {cond_std_diff:.3f}\")\n",
        "            print(f\"      from uncond: {diff:+.3f}\\n\")\n",
        "\n",
        "        print(\"=\"*70)\n",
        "        print(\"CONDITIONAL VS UNCONDITIONAL COMPARISON\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"{'Scale':<10} {'Uncond':<12} {'Cond':<12} {'':<12} {'%Change':<12}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        for scale in conditional_scales:\n",
        "            uncond = results['unconditional']['mean_difficulty']\n",
        "            cond = results['conditional_by_scale'][scale]['mean_difficulty']\n",
        "            diff = cond - uncond\n",
        "            pct = (diff / uncond * 100) if uncond != 0 else 0\n",
        "\n",
        "            print(f\"{scale:<10.1f} {uncond:<12.3f} {cond:<12.3f} {diff:<+12.3f} {pct:<+12.1f}%\")\n",
        "\n",
        "            results['comparison_table'].append({\n",
        "                'scale': scale,\n",
        "                'uncond': uncond,\n",
        "                'cond': cond,\n",
        "                'diff': diff,\n",
        "                'pct_change': pct\n",
        "            })\n",
        "\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        print(\"\\nStep 3: Testing if different playability targets produce different outputs...\")\n",
        "        if len(conditional_scales) >= 2:\n",
        "            scale_test = conditional_scales[0]\n",
        "            diff_low_high = abs(\n",
        "                np.mean(results['conditional_by_scale'][scale_test]['difficulties']) -\n",
        "                results['unconditional']['mean_difficulty']\n",
        "            )\n",
        "            print(f\" Different targets produce different outputs: diff = {diff_low_high:.4f}\")\n",
        "\n",
        "        print(\"\\n All CFG comparison tests complete!\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "        if save_path:\n",
        "            with open(save_path, 'w') as f:\n",
        "                f.write(\"CONDITIONAL VS UNCONDITIONAL COMPARISON\\n\")\n",
        "                f.write(\"=\"*70 + \"\\n\")\n",
        "                f.write(f\"Target Playability: {target_playability}\\n\")\n",
        "                f.write(f\"Patches per condition: {num_patches}\\n\\n\")\n",
        "\n",
        "                f.write(f\"{'Scale':<10} {'Uncond':<12} {'Cond':<12} {'':<12} {'%Change':<12}\\n\")\n",
        "                f.write(\"-\"*70 + \"\\n\")\n",
        "\n",
        "                for row in results['comparison_table']:\n",
        "                    f.write(f\"{row['scale']:<10.1f} {row['uncond']:<12.3f} {row['cond']:<12.3f} \"\n",
        "                          f\"{row['diff']:<+12.3f} {row['pct_change']:<+12.1f}%\\n\")\n",
        "\n",
        "            print(f\" Results saved to {save_path}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_difficulty_comparison(self,\n",
        "                                      sampler,\n",
        "                                      normalizer,\n",
        "                                      autoencoder,\n",
        "                                      parser,\n",
        "                                      difficulty_evaluator,\n",
        "                                      target_difficulties: List[float] = [0.2, 0.4, 0.6, 0.8, 1.0],\n",
        "                                      num_samples_per_target: int = 5,\n",
        "                                      guidance_scale: float = 3.0,\n",
        "                                      temperature: float = 0.5,\n",
        "                                      device: str = 'cuda',\n",
        "                                      save_path: Optional[str] = None) -> Dict:\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"DIFFICULTY EVALUATION COMPARISON\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Target difficulties: {target_difficulties}\")\n",
        "        print(f\"Samples per target: {num_samples_per_target}\")\n",
        "        print(f\"Guidance Scale: {guidance_scale}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        results = {\n",
        "            'target_difficulties': target_difficulties,\n",
        "            'evaluations': [],\n",
        "            'summary': {}\n",
        "        }\n",
        "\n",
        "        all_targets = []\n",
        "        all_actual_scores = []\n",
        "\n",
        "        for target_play in target_difficulties:\n",
        "            print(f\"\\nGenerating {num_samples_per_target} patches with target playability = {target_play}...\")\n",
        "\n",
        "            target_scores = []\n",
        "            actual_scores = []\n",
        "            patches_list = []\n",
        "\n",
        "            for sample_idx in range(num_samples_per_target):\n",
        "                latent = sampler.sample_single_patch(\n",
        "                    normalizer=normalizer,\n",
        "                    previous_latent=None,\n",
        "                    target_playability=target_play,\n",
        "                    previous_difficulties=None,\n",
        "                    temperature=temperature,\n",
        "                    guidance_scale=guidance_scale,\n",
        "                    show_progress=False\n",
        "                )\n",
        "\n",
        "                latent_denorm = normalizer.denormalize(latent.unsqueeze(0))\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    latent_denorm = latent_denorm.to(device)\n",
        "                    decoded_logits = autoencoder.decoder(latent_denorm)\n",
        "\n",
        "                    if decoded_logits.dim() == 4:\n",
        "                        patch = torch.argmax(decoded_logits, dim=1)\n",
        "                    elif decoded_logits.dim() == 3:\n",
        "                        patch = decoded_logits.long()\n",
        "                    elif decoded_logits.dim() == 5:\n",
        "                        decoded_logits = decoded_logits.squeeze(1)\n",
        "                        patch = torch.argmax(decoded_logits, dim=1)\n",
        "                    else:\n",
        "                        patch = torch.argmax(decoded_logits, dim=-1)\n",
        "\n",
        "                    patch = patch.cpu().numpy()[0]\n",
        "\n",
        "                eval_result = difficulty_evaluator.evaluate_patch(\n",
        "                    patch,\n",
        "                    metadata={'target_playability': target_play, 'sample_idx': sample_idx}\n",
        "                )\n",
        "\n",
        "                difficulty_score = eval_result['scores']['difficulty_score']\n",
        "\n",
        "                target_scores.append(target_play)\n",
        "                actual_scores.append(difficulty_score)\n",
        "                patches_list.append(patch)\n",
        "\n",
        "                all_targets.append(target_play)\n",
        "                all_actual_scores.append(difficulty_score)\n",
        "\n",
        "                results['evaluations'].append({\n",
        "                    'target_playability': target_play,\n",
        "                    'actual_difficulty': difficulty_score,\n",
        "                    'sample_idx': sample_idx,\n",
        "                    'patch': patch,\n",
        "                    'full_evaluation': eval_result\n",
        "                })\n",
        "\n",
        "            mean_actual = np.mean(actual_scores)\n",
        "            std_actual = np.std(actual_scores)\n",
        "\n",
        "            results['summary'][target_play] = {\n",
        "                'mean_difficulty': mean_actual,\n",
        "                'std_difficulty': std_actual,\n",
        "                'target_playability': target_play,\n",
        "                'error': abs(mean_actual - target_play),\n",
        "                'samples': actual_scores\n",
        "            }\n",
        "\n",
        "            print(f\"  Target: {target_play:.2f} | \"\n",
        "                  f\"Actual Difficulty: {mean_actual:.3f}  {std_actual:.3f} | \"\n",
        "                  f\"Error: {abs(mean_actual - target_play):.3f}\")\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        ax1 = axes[0, 0]\n",
        "        target_vals = list(results['summary'].keys())\n",
        "        mean_vals = [results['summary'][t]['mean_difficulty'] for t in target_vals]\n",
        "        std_vals = [results['summary'][t]['std_difficulty'] for t in target_vals]\n",
        "\n",
        "        ax1.errorbar(target_vals, mean_vals, yerr=std_vals,\n",
        "                    fmt='o', markersize=8, capsize=5, capthick=2,\n",
        "                    label='Generated (Mean  Std)', color='blue', alpha=0.7)\n",
        "        ax1.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect Alignment', alpha=0.5)\n",
        "        ax1.set_xlabel('Target Playability', fontsize=12, fontweight='bold')\n",
        "        ax1.set_ylabel('Actual Difficulty Score', fontsize=12, fontweight='bold')\n",
        "        ax1.set_title('Target vs Actual Difficulty (Aggregated)', fontsize=14, fontweight='bold')\n",
        "        ax1.legend(fontsize=10)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_xlim(-0.05, 1.05)\n",
        "        ax1.set_ylim(-0.05, 1.05)\n",
        "\n",
        "        ax2 = axes[0, 1]\n",
        "        ax2.scatter(all_targets, all_actual_scores, alpha=0.5, s=50, color='green')\n",
        "        ax2.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect Alignment', alpha=0.5)\n",
        "        ax2.set_xlabel('Target Playability', fontsize=12, fontweight='bold')\n",
        "        ax2.set_ylabel('Actual Difficulty Score', fontsize=12, fontweight='bold')\n",
        "        ax2.set_title('All Individual Samples', fontsize=14, fontweight='bold')\n",
        "        ax2.legend(fontsize=10)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.set_xlim(-0.05, 1.05)\n",
        "        ax2.set_ylim(-0.05, 1.05)\n",
        "\n",
        "        ax3 = axes[1, 0]\n",
        "        errors = [results['summary'][t]['error'] for t in target_vals]\n",
        "        ax3.bar(range(len(target_vals)), errors, color='orange', alpha=0.7, edgecolor='black')\n",
        "        ax3.set_xticks(range(len(target_vals)))\n",
        "        ax3.set_xticklabels([f'{t:.1f}' for t in target_vals])\n",
        "        ax3.set_xlabel('Target Playability', fontsize=12, fontweight='bold')\n",
        "        ax3.set_ylabel('Absolute Error', fontsize=12, fontweight='bold')\n",
        "        ax3.set_title('Prediction Error by Target', fontsize=14, fontweight='bold')\n",
        "        ax3.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "        ax4 = axes[1, 1]\n",
        "        data_for_box = [results['summary'][t]['samples'] for t in target_vals]\n",
        "        bp = ax4.boxplot(data_for_box, positions=range(len(target_vals)),\n",
        "                        widths=0.6, patch_artist=True,\n",
        "                        boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
        "                        medianprops=dict(color='red', linewidth=2))\n",
        "        ax4.plot(range(len(target_vals)), target_vals, 'go-',\n",
        "                linewidth=2, markersize=8, label='Target', alpha=0.7)\n",
        "        ax4.set_xticks(range(len(target_vals)))\n",
        "        ax4.set_xticklabels([f'{t:.1f}' for t in target_vals])\n",
        "        ax4.set_xlabel('Target Playability', fontsize=12, fontweight='bold')\n",
        "        ax4.set_ylabel('Difficulty Score Distribution', fontsize=12, fontweight='bold')\n",
        "        ax4.set_title('Distribution of Generated Difficulties', fontsize=14, fontweight='bold')\n",
        "        ax4.legend(fontsize=10)\n",
        "        ax4.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"\\n Evaluation plot saved to {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\n{'='*90}\")\n",
        "        print(f\"DETAILED EVALUATION RESULTS\")\n",
        "        print(f\"{'='*90}\")\n",
        "        print(f\"{'Target':<10} {'Generated':<12} {'Std Dev':<12} {'Error':<12} {'% Error':<12} {'Range':<20}\")\n",
        "        print(f\"{'-'*90}\")\n",
        "\n",
        "        for target in target_vals:\n",
        "            summary = results['summary'][target]\n",
        "            samples = summary['samples']\n",
        "            range_str = f\"[{min(samples):.3f}, {max(samples):.3f}]\"\n",
        "            pct_error = (summary['error'] / target * 100) if target != 0 else 0\n",
        "            print(f\"{target:<10.2f} {summary['mean_difficulty']:<12.3f} \"\n",
        "                  f\"{summary['std_difficulty']:<12.3f} {summary['error']:<12.3f} \"\n",
        "                  f\"{pct_error:<12.1f}% {range_str:<20}\")\n",
        "\n",
        "        overall_mae = np.mean([results['summary'][t]['error'] for t in target_vals])\n",
        "        overall_correlation = np.corrcoef(all_targets, all_actual_scores)[0, 1]\n",
        "\n",
        "        print(f\"\\n{'='*90}\")\n",
        "        print(f\"OVERALL STATISTICS\")\n",
        "        print(f\"{'='*90}\")\n",
        "        print(f\"Mean Absolute Error (MAE): {overall_mae:.4f}\")\n",
        "        print(f\"Correlation Coefficient: {overall_correlation:.4f}\")\n",
        "        print(f\"Total Samples Generated: {len(all_targets)}\")\n",
        "        print(f\"{'='*90}\\n\")\n",
        "\n",
        "        results['overall'] = {\n",
        "            'mae': overall_mae,\n",
        "            'correlation': overall_correlation,\n",
        "            'total_samples': len(all_targets)\n",
        "        }\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8f-vGdL1yxM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from typing import Optional\n",
        "\n",
        "def generate_levels(\n",
        "    num_levels: int = 5,\n",
        "    patches_per_level: int = 20,\n",
        "    difficulty_target: float = 1.0,\n",
        "    autoencoder_path: str = '/content/Output/AutoEncoder.pth',\n",
        "    diffusion_path: str = '/content/Output/conditional_diffusion_best.pth',\n",
        "    temperature: float = 0.9,\n",
        "    guidance_scale: float = 2.0,\n",
        "    parser=None,\n",
        "    stitcher_class=None,\n",
        "    autoencoder_class=None,\n",
        "    device: Optional[str] = None\n",
        "):\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(f\"GENERATING PLAYABLE LEVELS (AUTOREGRESSIVE)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    device = device if device is not None else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "\n",
        "    autoencoder = autoencoder_class(\n",
        "        num_tile_types=13,\n",
        "        embedding_dim=32,\n",
        "        latent_dim=128,\n",
        "        patch_height=14,\n",
        "        patch_width=16\n",
        "    )\n",
        "\n",
        "    ae_checkpoint = torch.load(autoencoder_path, map_location=device)\n",
        "\n",
        "    state = ae_checkpoint['model_state_dict']\n",
        "\n",
        "    try:\n",
        "        autoencoder.load_state_dict(state)\n",
        "    except Exception as e:\n",
        "        missing, unexpected = autoencoder.load_state_dict(state, strict=False)\n",
        "        print(\"Warning: loaded autoencoder with strict=False. Missing keys:\", missing, \"Unexpected:\", unexpected)\n",
        "    autoencoder.to(device)\n",
        "    autoencoder.eval()\n",
        "    print(\" Autoencoder loaded\")\n",
        "    unet = DiffusionUNet(\n",
        "        latent_dim=128,\n",
        "        time_emb_dim=256,\n",
        "        context_emb_dim=128,\n",
        "        hidden_dims=[256, 512, 512],\n",
        "        num_res_blocks=2,\n",
        "    ).to(device)\n",
        "\n",
        "    diff_checkpoint = torch.load(diffusion_path, map_location=device)\n",
        "    unet_state = diff_checkpoint['unet_state_dict']\n",
        "\n",
        "\n",
        "    try:\n",
        "        unet.load_state_dict(unet_state)\n",
        "    except Exception as e:\n",
        "        missing, unexpected = unet.load_state_dict(unet_state, strict=False)\n",
        "        print(\"Warning: loaded UNet with strict=False. Missing keys:\", missing, \"Unexpected:\", unexpected)\n",
        "\n",
        "    unet.to(device)\n",
        "    unet.eval()\n",
        "    print(\" Autoregressive Diffusion U-Net loaded\")\n",
        "    schedule = NoiseSchedule(\n",
        "        num_timesteps=500,\n",
        "        schedule_type='linear',\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    normalizer = LatentNormalizer(target_norm=11.0)\n",
        "    normalizer.load('Output/latent_normalizer.pth')\n",
        "\n",
        "    sampler = Sampler(\n",
        "        unet,\n",
        "        schedule,\n",
        "        device=device\n",
        "    )\n",
        "    print(\" Autoregressive sampler initialized\")\n",
        "    stitcher = stitcher_class(patch_height=14, patch_width=16, stride=4)\n",
        "    generated_levels = []\n",
        "\n",
        "\n",
        "    for level_idx in range(num_levels):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Generating Level {level_idx + 1}/{num_levels}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        print(f\"Generating {patches_per_level} patches sequentially (autoregressive)...\")\n",
        "        for attr in ['scale','mean','target_norm','original_norm','scale_factor']:\n",
        "            if hasattr(normalizer, attr):\n",
        "                print(attr, getattr(normalizer, attr))\n",
        "            else:\n",
        "                print(\"no attr\", attr)\n",
        "\n",
        "        latents = sampler.sample_level(\n",
        "            num_patches=patches_per_level,\n",
        "            normalizer=normalizer,\n",
        "            difficulty_target=difficulty_target,\n",
        "            temperature=temperature,\n",
        "            guidance_scale=guidance_scale,\n",
        "            show_progress=True,\n",
        "        )\n",
        "\n",
        "        latents_denorm = normalizer.denormalize(latents)\n",
        "\n",
        "        import math\n",
        "        print(\"normalizer attributes:\")\n",
        "        for a in [\"scale_factor\",\"target_norm\",\"original_mean_norm\",\"original_std_norm\"]:\n",
        "            if hasattr(normalizer, a):\n",
        "                print(f\"  {a} =\", getattr(normalizer, a))\n",
        "            else:\n",
        "                print(f\"  {a} = <missing>\")\n",
        "\n",
        "        print(\"\\nRaw sampler stats (per-dim):\", \"min/max:\", float(latents.min()), float(latents.max()))\n",
        "        print(\"Raw mean/std (per-dim):\", float(latents.mean()), float(latents.std()))\n",
        "\n",
        "        ld = latents_denorm.detach().cpu()\n",
        "        print(\"\\nDenorm per-dim stats: mean/std:\", float(ld.mean()), float(ld.std()))\n",
        "        print(\"Denorm min/max:\", float(ld.min()), float(ld.max()))\n",
        "\n",
        "        l2 = ld.norm(dim=-1)\n",
        "        print(\"\\nL2 norms (denorm) stats: mean/std/min/max:\", float(l2.mean()), float(l2.std()), float(l2.min()), float(l2.max()))\n",
        "        print(\"\\nExpected training L2 mean/std (what you expect):\", \"mean=11, std=1 (confirm these are the intended metrics)\")\n",
        "\n",
        "        z_test = torch.randn(1000, ld.shape[1])\n",
        "        z_test_den = normalizer.denormalize(z_test)\n",
        "        print(\"\\nTest mapping for std-normal inputs -> denorm mean/std (per-dim):\", float(z_test_den.mean()), float(z_test_den.std()))\n",
        "        print(\"Test mapping L2 norm mean/std:\", float(z_test_den.norm(dim=-1).mean()), float(z_test_den.norm(dim=-1).std()))\n",
        "\n",
        "        if not torch.is_tensor(latents_denorm):\n",
        "            raise RuntimeError(\"Sampler did not return a torch.Tensor. Got: %s\" % type(latents_denorm))\n",
        "\n",
        "        assert latents_denorm.dim() == 2 and latents_denorm.shape[0] == patches_per_level, \\\n",
        "            f\"Expected latents shape [num_patches, latent_dim], got {latents_denorm.shape}\"\n",
        "\n",
        "        print(f\" Generated {latents_denorm.shape[0]} latents (shape: {latents_denorm.shape})\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            latents_denorm = latents_denorm.to(device)\n",
        "            decoded_logits = autoencoder.decoder(latents_denorm)\n",
        "\n",
        "            if decoded_logits.dim() == 4:\n",
        "                patches = torch.argmax(decoded_logits, dim=1)\n",
        "            elif decoded_logits.dim() == 3:\n",
        "                patches = decoded_logits.long()\n",
        "            elif decoded_logits.dim() == 5:\n",
        "                decoded_logits = decoded_logits.squeeze(1)\n",
        "                patches = torch.argmax(decoded_logits, dim=1)\n",
        "            else:\n",
        "                patches = torch.argmax(decoded_logits, dim=-1)\n",
        "\n",
        "        patches_np = patches.cpu().numpy()\n",
        "\n",
        "        if patches_np.shape[1] != stitcher.patch_height:\n",
        "            print(f\"Warning: patch height mismatch: decoded H={patches_np.shape[1]}, stitcher.patch_height={stitcher.patch_height}\")\n",
        "\n",
        "        level = stitcher.stitch_patches_to_level(patches_np)\n",
        "\n",
        "        print(f\"\\n--- Generated Level {level_idx + 1} ---\")\n",
        "        level_str = parser.decode_level(level)\n",
        "        print(level_str)\n",
        "\n",
        "        output_path = f'/content/Output/autoregressive_level_{level_idx+1}.txt'\n",
        "        with open(output_path, 'w') as f:\n",
        "            f.write(level_str)\n",
        "        print(f\" Saved to {output_path}\")\n",
        "\n",
        "        generated_levels.append(level)\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" GENERATION COMPLETE! Generated {len(generated_levels)} levels\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    return generated_levels, sampler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ3-0L4PFctP",
        "outputId": "6ebc2675-4f5b-40b1-faae-79b3c401d487"
      },
      "outputs": [],
      "source": [
        "len(all_difficulties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yWEJuZvL4qEk",
        "outputId": "0bb38061-a0f7-46f1-9dae-f7776f8e18ce"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "print(\"STEP 1: Training conditional diffusion model...\")\n",
        "trainer, unet, val_loader = train_conditional_diffusion_model(\n",
        "    latents=latents_norm,\n",
        "    metadata=metadata,\n",
        "    autoencoder_path='/content/Output/AutoEncoder.pth',\n",
        "    save_path='/content/Output/conditional_diffusion.pth',\n",
        "    num_epochs=200,\n",
        "    batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2FcCpgeiBO3",
        "outputId": "e26df04e-591d-401d-9a52-13540c831d8a"
      },
      "outputs": [],
      "source": [
        "def test_cfg_architecture():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TESTING CFG ARCHITECTURE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    model = DiffusionUNet(\n",
        "        latent_dim=128,\n",
        "        time_emb_dim=256,\n",
        "        context_emb_dim=128,\n",
        "        hidden_dims=[256, 512, 512],\n",
        "        num_res_blocks=2,\n",
        "        cond_dropout=0.15\n",
        "    ).to(device)\n",
        "\n",
        "    batch_size = 4\n",
        "    x = torch.randn(batch_size, 128, device=device)\n",
        "    t = torch.randint(0, 500, (batch_size,), device=device)\n",
        "    prev_lat = torch.randn(batch_size, 5, 128, device=device)\n",
        "    prev_play = torch.rand(batch_size, 5, device=device)\n",
        "\n",
        "    target_play = torch.rand(batch_size, device=device)\n",
        "    noise_cond = model(x, t, prev_lat, prev_play, target_playability=target_play)\n",
        "    print(f\" Conditional forward works: output shape = {noise_cond.shape}\")\n",
        "\n",
        "    noise_uncond = model(x, t, prev_lat, prev_play, target_playability=None)\n",
        "    print(f\" Unconditional forward works: output shape = {noise_uncond.shape}\")\n",
        "\n",
        "    diff = (noise_cond - noise_uncond).abs().mean().item()\n",
        "    print(f\" Cond vs Uncond difference: {diff:.4f}\")\n",
        "\n",
        "    guidance_scale = 3.0\n",
        "    noise_guided = noise_uncond + guidance_scale * (noise_cond - noise_uncond)\n",
        "    print(f\" CFG formula works: output shape = {noise_guided.shape}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        target_low = torch.full((batch_size,), 0.1, device=device)\n",
        "        target_high = torch.full((batch_size,), 0.9, device=device)\n",
        "\n",
        "        noise_low = model(x, t, prev_lat, prev_play, target_playability=target_low)\n",
        "        noise_high = model(x, t, prev_lat, prev_play, target_playability=target_high)\n",
        "\n",
        "        diff_targets = (noise_low - noise_high).abs().mean().item()\n",
        "        print(f\" Different targets produce different noise: diff = {diff_targets:.4f}\")\n",
        "\n",
        "    print(\"\\n All CFG architecture tests passed!\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_cfg_architecture()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lokBiFqvRcsr",
        "outputId": "1f1be132-7371-4e2d-b4f0-89210a0c4810"
      },
      "outputs": [],
      "source": [
        "stitcher = PatchStitcher()\n",
        "scheduler = NoiseSchedule(num_timesteps=500, schedule_type='linear')\n",
        "sampler = Sampler(unet, scheduler)\n",
        "difficulty_evaluator = PatchDifficultyEvaluator(parser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ub9hPW5aHmSK",
        "outputId": "506376e5-3ed8-4324-b762-41c2560a1ba1"
      },
      "outputs": [],
      "source": [
        "eval_results = stitcher.evaluate_difficulty_comparison(\n",
        "    sampler=sampler,\n",
        "    normalizer=normalizer,\n",
        "    autoencoder=autoencoder,\n",
        "    parser=parser,\n",
        "    difficulty_evaluator=difficulty_evaluator,\n",
        "    target_difficulties=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
        "    num_samples_per_target=1,\n",
        "    temperature = 0.5,\n",
        "    guidance_scale=5.0,\n",
        "    save_path='/content/Output/difficulty_evaluation.png'\n",
        ")\n",
        "\n",
        "# Check overall performance\n",
        "print(f\"MAE: {eval_results['overall']['mae']:.4f}\")\n",
        "print(f\"Correlation: {eval_results['overall']['correlation']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFe59QN9RW_e",
        "outputId": "4af341b4-2307-4b85-8ae0-ee42cd0a8e53"
      },
      "outputs": [],
      "source": [
        "results = stitcher.compare_cfg_difficulty(\n",
        "    sampler=sampler,\n",
        "    normalizer=normalizer,\n",
        "    autoencoder=autoencoder,\n",
        "    difficulty_evaluator=difficulty_evaluator,\n",
        "    parser=parser,\n",
        "    guidance_scales=[0.0, 1.0, 2.0, 3.0, 5.0, 7.0],\n",
        "    num_patches=1,\n",
        "    target_playability=1.0,\n",
        "    save_path='/content/Output/cfg_comparison.png'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TADrit92inGx",
        "outputId": "4a444b22-22cd-4c29-8a02-d062a098968b"
      },
      "outputs": [],
      "source": [
        "levels, sampler = generate_levels(\n",
        "    num_levels=1,\n",
        "    patches_per_level=20,\n",
        "    parser=parser,\n",
        "    difficulty_target = 1.0,\n",
        "    temperature=0.2,\n",
        "    guidance_scale = 5,\n",
        "    stitcher_class=PatchStitcher,\n",
        "    autoencoder_class=Autoencoder,\n",
        "    diffusion_path = '/content/Output/conditional_diffusion.pth'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZPi4_QHv8zpG"
      },
      "outputs": [],
      "source": [
        "!pip install mario_gpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk_Smq8wWz5E"
      },
      "outputs": [],
      "source": [
        "from mario_gpt import MarioDataset, MarioLM\n",
        "from mario_gpt.utils import view_level, convert_level_to_png, join_list_of_list, characterize\n",
        "\n",
        "mario_lm = MarioLM()\n",
        "\n",
        "test = \"\"\"----------------\n",
        "----------------\n",
        "----------------\n",
        "----------------\n",
        "----------------\n",
        "---------E-E----\n",
        "--------<><>----\n",
        "------[][][]----\n",
        "------QQQQQQ----\n",
        "----------------\n",
        "----------------\n",
        "----------------\n",
        "----------------\n",
        "XXXX--XXX-XXXXXX\"\"\".split(\"\\n\")\n",
        "\n",
        "testing = convert_level_to_png(test,  mario_lm.tokenizer)[0]\n",
        "testing"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
